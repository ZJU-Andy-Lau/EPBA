import os
import cv2
from datetime import datetime
import pandas as pd
from pathlib import Path
from tqdm import tqdm
from skimage.transform import AffineTransform
from skimage.measure import ransac
from PIL import Image
import numpy as np
from copy import deepcopy
import torch
import torch.nn as nn
import torch.nn.init as init
import torch.nn.functional as F
import torch.distributed as dist
import random
import argparse
from .rpc import RPCModelParameterTorch
from typing import Tuple
from sklearn.decomposition import PCA
from enum import Enum
from sklearn.preprocessing import MinMaxScaler
from matplotlib.patches import ConnectionPatch
from matplotlib import pyplot as plt
import io
from shapely.geometry import Polygon, Point
from shapely.affinity import scale
import math
from typing import List
import yaml

def get_current_time():
    """
    return: %Y%m%d%H%M%S
    """
    return datetime.now().strftime("%Y%m%d%H%M%S")

def debug_print(msg,once = True):
    if not once or dist.get_rank() == 0:
        print(f"[rank {dist.get_rank()}]:{msg}")

def load_config(path):
    with open(path,'r') as f:
        config = yaml.safe_load(f)
    return config

def feats_pca(feats:np.ndarray):
    if feats.ndim == 3:
        feats = feats[None]
    B,H,W,C = feats.shape
    feats = feats.reshape(-1,C)
    pca = PCA(n_components=3)
    feats = pca.fit_transform(feats)
    feats = 255. * (feats - feats.min()) / (feats.max() - feats.min())
    feats = feats.reshape(B,H,W,3).astype(np.uint8)
    if B == 1:
        feats = feats.squeeze(0)
    return feats

def check_grad(input:torch.Tensor,name = ''):
    if input.grad is None:
        print(f"tensor {name} has no grad")
    else:
        zero_grads = torch.sum(input.grad == 0).item()
        print(f"tensor {name} has {zero_grads} zero grad elements")

def check_invalid_tensors(tensor_list: List[torch.Tensor],note = ""):
    """
    æ£€æŸ¥ List[torch.Tensor] ä¸­çš„æ¯ä¸ªå¼ é‡æ˜¯å¦å«æœ‰ NaN (éæ•°å­—) æˆ– Inf (æ— ç©·å¤§) å€¼ã€‚
    å¦‚æœå‘ç°å¼‚å¸¸å€¼ï¼Œåˆ™æ‰“å°è¯¥å¼ é‡åœ¨ List ä¸­çš„ç´¢å¼•ã€‚

    Args:
        tensor_list (List[torch.Tensor]): å¾…æ£€æŸ¥çš„ PyTorch å¼ é‡åˆ—è¡¨ã€‚
    """
    
    # è®¡æ•°å™¨ç”¨äºè®°å½•å‘ç°çš„å¼‚å¸¸å¼ é‡æ•°é‡
    abnormal_count = 0
    
    print(f"--- {note}å¼€å§‹æ£€æŸ¥å¼ é‡åˆ—è¡¨ä¸­çš„ NaN/Inf å€¼ ---")
    
    for idx, tensor in enumerate(tensor_list):
        # ä»…æ£€æŸ¥æµ®ç‚¹æ•°å¼ é‡ï¼Œå› ä¸ºæ•´æ•°å¼ é‡é€šå¸¸ä¸åŒ…å« NaN/Inf
        if tensor.dtype.is_floating_point:
            
            # 1. æ£€æŸ¥ NaN
            # torch.isnan(tensor).any() å¦‚æœå¼ é‡ä¸­è‡³å°‘æœ‰ä¸€ä¸ª NaNï¼Œåˆ™è¿”å› True
            has_nan = torch.isnan(tensor).any()
            
            # 2. æ£€æŸ¥ Inf
            # torch.isinf(tensor).any() å¦‚æœå¼ é‡ä¸­è‡³å°‘æœ‰ä¸€ä¸ª Â±Infï¼Œåˆ™è¿”å› True
            has_inf = torch.isinf(tensor).any()
            
            if has_nan or has_inf:
                abnormal_count += 1
                
                # æ„é€ åŒ…å«å…·ä½“å¼‚å¸¸ç±»å‹çš„æŠ¥å‘Š
                report = []
                if has_nan:
                    report.append("NaN")
                if has_inf:
                    report.append("Inf")
                
                print(f"ğŸš¨ å¼‚å¸¸å¼ é‡å‘ç°ï¼šç´¢å¼• {idx} åŒ…å«ä»¥ä¸‹å€¼: {', '.join(report)}ã€‚")
                print(f"    - å½¢çŠ¶: {tensor.shape}")
                print(f"    - æ•°æ®ç±»å‹: {tensor.dtype}")
        
    if abnormal_count == 0:
        print("âœ… æ£€æŸ¥å®Œæ¯•ï¼šæ‰€æœ‰å¼ é‡å‡æœªå‘ç° NaN æˆ– Inf å€¼ã€‚")
    else:
        print(f"âš ï¸ æ£€æŸ¥å®Œæ¯•ï¼šå…±å‘ç° {abnormal_count} ä¸ªå¼‚å¸¸å¼ é‡ã€‚")

def load_model_state_dict(model:nn.Module,state_dict_path:str):
    state_dict = torch.load(state_dict_path,map_location='cpu')
    state_dict = {k.replace("module.",""):v for k,v in state_dict.items()}
    model.load_state_dict(state_dict,strict=False)
    return model

def crop_rect_from_image(image, rect_points, size):
    """
    ä»å›¾åƒä¸­æˆªå–çŸ©å½¢åŒºåŸŸã€‚

    å‚æ•°:
    - image: ä½¿ç”¨cv2.imread()è¯»å–çš„å›¾åƒã€‚
    - rect_points: çŸ©å½¢çš„å››ä¸ªé¡¶ç‚¹åæ ‡ï¼ŒæŒ‰é¡ºæ—¶é’ˆæˆ–é€†æ—¶é’ˆé¡ºåºæ’åˆ—ã€‚
                  ä¾‹å¦‚: [(x1, y1), (x2, y2), (x3, y3), (x4, y4)]

    è¿”å›:
    - cropped_image: æˆªå–å‡ºçš„çŸ©å½¢å›¾åƒã€‚
    """
    # å°†å››ä¸ªé¡¶ç‚¹è½¬æ¢ä¸ºnumpyæ•°ç»„
    rect = np.array(rect_points, dtype="float32")

    # è®¡ç®—çŸ©å½¢çš„è¾¹ç•Œæ¡†çš„å®½åº¦å’Œé«˜åº¦
    width_a = np.linalg.norm(rect[0] - rect[1])
    width_b = np.linalg.norm(rect[2] - rect[3])
    max_width = int(max(width_a, width_b))

    height_a = np.linalg.norm(rect[0] - rect[3])
    height_b = np.linalg.norm(rect[1] - rect[2])
    max_height = int(max(height_a, height_b))

    # ç›®æ ‡çŸ©å½¢çš„å››ä¸ªè§’çš„åæ ‡ï¼ˆä»¿å°„å˜æ¢åçš„åæ ‡ï¼‰
    dst = np.array([[0, 0], [0, max_width-1], [max_height-1, max_width-1], [max_height-1, 0]], dtype="float32")

    rect_xy = np.array([[p[1],p[0]] for p in rect], dtype="float32")
    dst_xy = np.array([[p[1],p[0]]for p in dst], dtype="float32")

    # è®¡ç®—ä»¿å°„å˜æ¢çŸ©é˜µ
    M = cv2.getPerspectiveTransform(rect_xy, dst_xy)
    M_inv = cv2.getPerspectiveTransform(dst, rect)

    # ä½¿ç”¨ä»¿å°„å˜æ¢å°†å›¾åƒä¸­çš„çŸ©å½¢åŒºåŸŸè½¬æ¢ä¸ºç›®æ ‡çŸ©å½¢åŒºåŸŸ
    warped = cv2.warpPerspective(image.astype(np.float32), M, (max_width, max_height))

    if warped.shape[0] < size or warped.shape[1] < size:
        warped = cv2.resize(warped,(size,size))

    return warped.astype(np.float32),M_inv

def random_square_cut_and_affine(images, square_size, angle = None, margin = None):
    H, W = images[0].shape[:2]
    
    if angle is None:
        angle = np.random.uniform(-5,5)  # éšæœºæ—‹è½¬è§’åº¦
    theta = np.deg2rad(angle)
    if margin is None:
        margin = int((np.abs(np.sin(theta)) + np.abs(np.cos(theta)))*square_size / 2) + 1
    center_x = np.random.uniform(margin + 1, W - margin - 1)
    center_y = np.random.uniform(margin + 1, H - margin - 1)
    # crop_upperleft = np.array([center_x - square_size / 2,center_y - square_size / 2],dtype=int)
    new_points = np.array([[-square_size / 2, -square_size / 2],
                        [ -square_size / 2, square_size / 2],
                        [ square_size / 2,  square_size / 2],
                        [square_size / 2,  -square_size / 2]])

    
    rotation_matrix = np.array([
        [np.cos(theta), -np.sin(theta)],
        [np.sin(theta),  np.cos(theta)]
    ])
    
    rotated_points = np.matmul(rotation_matrix,new_points.T).T + np.array([center_x, center_y])
    res = [crop_rect_from_image(image,rotated_points,square_size) for image in images]
    af_mat = res[0][1]

    return [i[0] for i in res],af_mat[:2,:],rotated_points


def estimate_affine_ransac(A, B, iterations=1000, threshold=0.1, whole=False, hp_num=3):
    max_inliers_num = 0
    best_affine_matrix = None

    def estimate_affine_transformation(A, B):
        # ä¸­å¿ƒåŒ–ç‚¹é›†
        A_centered = A - np.mean(A, axis=0)
        B_centered = B - np.mean(B, axis=0)

        # è®¡ç®—åæ–¹å·®çŸ©é˜µ
        H = A_centered.T @ B_centered

        # è¿›è¡Œå¥‡å¼‚å€¼åˆ†è§£
        U, S, Vt = np.linalg.svd(H)

        # è®¡ç®—æ—‹è½¬çŸ©é˜µ
        R = Vt.T @ U.T

        # ç¡®ä¿æ—‹è½¬çŸ©é˜µçš„è¡Œåˆ—å¼ä¸º1
        if np.linalg.det(R) < 0:
            Vt[1, :] *= -1
            R = Vt.T @ U.T

        # è®¡ç®—å¹³ç§»
        t = np.mean(B, axis=0) - R @ np.mean(A, axis=0)

        # ç»„åˆæˆä»¿å°„å˜æ¢çŸ©é˜µ
        affine_matrix = np.eye(3)
        affine_matrix[:2, :2] = R
        affine_matrix[:2, 2] = t

        return affine_matrix

    for _ in range(iterations):
        # éšæœºé€‰æ‹©ä¸‰ä¸ªç‚¹
        sample_indices = random.sample(range(len(A)), hp_num)
        A_sample = A[sample_indices]
        B_sample = B[sample_indices]

        # è®¡ç®—ä»¿å°„å˜æ¢çŸ©é˜µ
        affine_matrix = estimate_affine_transformation(A_sample, B_sample)

        # è®¡ç®—åœ¨å½“å‰å˜æ¢ä¸‹çš„é¢„æµ‹å€¼
        B_pred = (affine_matrix[:2, :2] @ A.T).T + affine_matrix[:2, 2]

        # è®¡ç®—å†…ç‚¹
        distances = np.linalg.norm(B - B_pred, axis=1)
        inliers = distances < threshold

        # æ›´æ–°æœ€ä½³å†…ç‚¹é›†
        if np.sum(inliers) > max_inliers_num:
            max_inliers_num = np.sum(inliers)
            if whole:
                whole_matrix = estimate_affine_transformation(A[inliers],B[inliers])
                B_pred = (whole_matrix[:2, :2] @ A.T).T + whole_matrix[:2, 2]
                # è®¡ç®—å†…ç‚¹
                distances = np.linalg.norm(B - B_pred, axis=1)
                inliers = distances < threshold
                if np.sum(inliers) > max_inliers_num:
                    max_inliers_num = np.sum(inliers)
                    best_affine_matrix = whole_matrix
                else:
                    best_affine_matrix = affine_matrix
            else:
                best_affine_matrix = affine_matrix

    return best_affine_matrix[:2,:], max_inliers_num

# def estimate_affine_ransac(points1, points2, threshold = 20):
#     model_robust, inliers = ransac((points1, points2), 
#                                 AffineTransform, 
#                                 min_samples=3, 
#                                 residual_threshold=threshold, 
#                                 max_trials=1000)
    
#     return model_robust.params[:2,:], len(inliers[inliers]) 

def calculate_errors(T_true, T_pred):
    # æå–æ—‹è½¬éƒ¨åˆ† (å‰2x2çŸ©é˜µ) å’Œ å¹³ç§»éƒ¨åˆ† (æœ€åä¸€åˆ—)
    R_true = T_true[:, :2]
    R_pred = T_pred[:, :2]
    
    t_true = T_true[:, 2]
    t_pred = T_pred[:, 2]
    
    # è®¡ç®—å¹³ç§»è¯¯å·®ï¼ˆæ¬§æ°è·ç¦»ï¼‰
    translation_error = np.linalg.norm(t_pred - t_true)
    
    # è®¡ç®—æ—‹è½¬è§’åº¦
    theta_true = np.arctan2(R_true[1, 0], R_true[0, 0])
    theta_pred = np.arctan2(R_pred[1, 0], R_pred[0, 0])
    
    # è®¡ç®—æ—‹è½¬è¯¯å·®ï¼ˆè§’åº¦å·®å¼‚ï¼‰
    rotation_error = np.degrees(np.abs(theta_pred - theta_true))
    
    return rotation_error, translation_error

class TableLogger():
    def __init__(self,folder_path:str,columns:list,prefix:str = 'log',name = None):
        self.df = pd.DataFrame(columns=columns)
        self.folder = folder_path
        if name is None:
            self.file_name = f"{prefix}_{datetime.now().strftime('%Y%m%d%H%M%S')}.csv"
        else:
            self.file_name = name
        self.path = os.path.join(self.folder,self.file_name)
        
        if not os.path.exists(self.path):
            self.df.to_csv(self.path,index=False)
        else:
            self.df = pd.read_csv(self.path)
    def update(self,row):
        try:
            self.df = self.df._append(row,ignore_index=True)
            self.df.to_csv(self.path,index=False)
        except:
            self.df = self.df.append(row,ignore_index=True)
            self.df.to_csv(self.path,index=False)

def average_downsample_matrix(matrix:np.ndarray, n):
    """
    å¯¹ç»™å®šçš„numpyçŸ©é˜µè¿›è¡Œnå€å¹³å‡ä¸‹é‡‡æ ·
    :param matrix: è¾“å…¥çš„numpyçŸ©é˜µ
    :param n: ä¸‹é‡‡æ ·å€æ•°
    :return: ä¸‹é‡‡æ ·åçš„çŸ©é˜µ
    """
    rows, cols = matrix.shape[:2]
    new_rows = rows // n
    new_cols = cols // n
    downsampled_matrix = np.zeros((new_rows, new_cols,*matrix.shape[2:]))
    for r in range(new_rows):
        for c in range(new_cols):
            downsampled_matrix[r, c] = matrix[r * n:(r + 1) * n, c * n:(c + 1) * n].mean(axis=(0,1))

    return downsampled_matrix

def avg_downsample(tensor:torch.Tensor, k: int) -> torch.Tensor:
    if tensor.ndim < 3:
        raise ValueError(f"è¾“å…¥å¼ é‡çš„ç»´åº¦å¿…é¡» >= 3ï¼Œå½“å‰ç»´åº¦ä¸º {tensor.ndim}")
        
    H, W = tensor.shape[1:3]
    if H % k != 0 or W % k != 0:
        raise ValueError(
            f"å¼ é‡çš„ H ({H}) å’Œ W ({W}) ç»´åº¦å¿…é¡»èƒ½è¢«ä¸‹é‡‡æ ·å€æ•° K ({k}) æ•´é™¤ã€‚"
        )

    rest_dims = tensor.shape[3:]
    num_channels = torch.prod(torch.tensor(rest_dims)).item() if len(rest_dims) > 0 else 1
    if len(rest_dims) == 0:
        reshaped_tensor = tensor.unsqueeze(-1) # å½¢çŠ¶å˜ä¸º (B, H, W, 1)
    else:
        reshaped_tensor = tensor.view(tensor.shape[0], H, W, num_channels)

    transposed_tensor = reshaped_tensor.permute(0, 3, 1, 2)
    downsampled_transposed = F.avg_pool2d(
        input=transposed_tensor,
        kernel_size=k,
        stride=k
    ) # å½¢çŠ¶ï¼š(B, C, H//K, W//K)

    final_tensor_flat = downsampled_transposed.permute(0, 2, 3, 1)
    output_shape = (
        tensor.shape[0], 
        H // k, 
        W // k
    ) + rest_dims
    
    final_tensor = final_tensor_flat.view(output_shape)
    
    return final_tensor

def get_coord_mat(H,W,downsample:int = 0):
    """
    return: [row,col] (H,W,2)
    """
    row_coords, col_coords = np.meshgrid(np.arange(0,H), np.arange(0,W), indexing='ij')
    coord_array = np.stack([row_coords, col_coords], axis=-1).astype(np.float32)  # (H,W, 2)
    if downsample > 0:
        coord_array = average_downsample_matrix(coord_array,downsample)
    return coord_array

def find_grids(quadrilaterals, side_length, offset_x=0.0, offset_y=0., grid_num = -1):
    # æ£€æŸ¥è¾“å…¥æ˜¯å¦æœ‰æ•ˆ
    if not isinstance(quadrilaterals, np.ndarray) or quadrilaterals.ndim != 3 or quadrilaterals.shape[1:] != (4, 2):
        raise ValueError("è¾“å…¥'quadrilaterals'å¿…é¡»æ˜¯å½¢çŠ¶ä¸º (N, 4, 2) çš„Numpyæ•°ç»„ã€‚")
    if not isinstance(side_length, (int, float)) or side_length <= 0:
        raise ValueError("è¾“å…¥'side_length'å¿…é¡»æ˜¯ä¸€ä¸ªæ­£æ•°ã€‚")
    if quadrilaterals.shape[0] == 0:
        return np.empty((0, 2, 2)), None

    def _order_points_for_polygon(points):
        # 1. è®¡ç®—è´¨å¿ƒ
        centroid = np.mean(points, axis=0)
        
        # 2. è®¡ç®—æ¯ä¸ªç‚¹ç›¸å¯¹äºè´¨å¿ƒçš„è§’åº¦
        angles = [math.atan2(p[1] - centroid[1], p[0] - centroid[0]) for p in points]
        
        # 3. æ ¹æ®è§’åº¦å¯¹ç‚¹è¿›è¡Œæ’åº
        sorted_points = sorted(zip(points, angles), key=lambda item: item[1])
        
        # è¿”å›æ’åºåçš„ç‚¹åæ ‡
        return np.array([p for p, a in sorted_points])

    # --- æ­¥éª¤ 1: å°†Numpyæ•°ç»„è½¬æ¢ä¸ºShapelyå¤šè¾¹å½¢å¯¹è±¡åˆ—è¡¨ ---
    try:
        # å·²ä¿®æ”¹ï¼šåœ¨åˆ›å»ºå¤šè¾¹å½¢å‰ï¼Œå…ˆå¯¹å…¶é¡¶ç‚¹è¿›è¡Œæ’åºï¼Œç¡®ä¿å¤šè¾¹å½¢æœ‰æ•ˆã€‚
        # .buffer(0) ä»ç„¶ä¿ç•™ï¼Œä½œä¸ºå¤„ç†å…¶ä»–æ½œåœ¨æ— æ•ˆæƒ…å†µçš„æœ€åé˜²çº¿ã€‚
        polygons = [Polygon(_order_points_for_polygon(q)).buffer(0) for q in quadrilaterals]
        polygons = [p for p in polygons if not p.is_empty]
        if not polygons:
             return np.empty((0, 2, 2)), None
    except Exception as e:
        raise ValueError(f"æ— æ³•æ ¹æ®è¾“å…¥åæ ‡åˆ›å»ºå¤šè¾¹å½¢: {e}")

    # --- æ­¥éª¤ 2: è®¡ç®—æ‰€æœ‰å¤šè¾¹å½¢çš„äº¤é›† ---
    intersection_area = polygons[0]
    for i in range(1, len(polygons)):
        intersection_area = intersection_area.intersection(polygons[i])
        if intersection_area.is_empty:
            return np.empty((0, 2, 2)), intersection_area

    if intersection_area.is_empty:
        return np.empty((0, 2, 2)), intersection_area

    # --- æ­¥éª¤ 3 & 4: åœ¨äº¤é›†çš„è¾¹ç•Œæ¡†å†…è¿›è¡Œç½‘æ ¼è¿­ä»£ ---
    found_squares_coords = []
    minx, miny, maxx, maxy = intersection_area.bounds

    x = minx
    while x + side_length <= maxx:
        y = miny
        while y + side_length <= maxy:
            # --- æ­¥éª¤ 5: åˆ›å»ºå€™é€‰æ­£æ–¹å½¢å¹¶æ£€æŸ¥æ˜¯å¦è¢«å®Œå…¨åŒ…å« ---
            square_poly = Polygon([
                (x, y),
                (x + side_length, y),
                (x + side_length, y + side_length),
                (x, y + side_length)
            ])

            if intersection_area.contains(square_poly):
                # æ‰¾åˆ°äº†ä¸€ä¸ªæœ‰æ•ˆçš„æ­£æ–¹å½¢ã€‚è®°å½•å…¶å·¦ä¸Šè§’å’Œå³ä¸‹è§’åæ ‡ï¼Œå¹¶åº”ç”¨åç§»
                top_left_offset = [x + offset_x, y + side_length + offset_y]
                bottom_right_offset = [x + side_length + offset_x, y + offset_y]
                found_squares_coords.append([top_left_offset, bottom_right_offset])
            
            y += side_length
        x += side_length

    diags = np.array(found_squares_coords) if found_squares_coords else np.empty((0, 2, 2))

    if grid_num > 0:
        diags = diags[:grid_num]
    
    return diags

def kaiming_init_weights(m):
    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):
        init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')
        if m.bias is not None:
            init.zeros_(m.bias)

def norm_init_weights(m):
    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):
        init.normal_(m.weight,0,0.001)
        if m.bias is not None:
            init.normal_(m.bias,0,0.001)

def str2bool(value):
    if isinstance(value, bool):
        return value
    if value.lower() in ("yes", "true", "t", "y", "1"):
        return True
    elif value.lower() in ("no", "false", "f", "n", "0"):
        return False
    else:
        raise argparse.ArgumentTypeError("Boolean value expected")

def warp_by_extend(points:torch.Tensor,extend:torch.Tensor):
    """
    points [x,y,h]
    return [y,x,h]
    """
    points = points.to(torch.double)
    extend = extend.to(torch.double).to(points.device)
    points[:,0] *= extend[6]
    points[:,1] *= extend[7] 
    points[:,2] = (points[:,2] + 1.) * (extend[9] - extend[8]) * 0.5 + extend[8]
    af_mat = extend[:6].reshape(2,3)
    R = af_mat[:2,:2]
    t = af_mat[:2,2]
    points[:,:2] = points[:,:2] @ R.T
    points[:,:2] = points[:,:2] + t
    points[:,[0,1]] = points[:,[1,0]]
    return points

def project_mercator(latlon:torch.Tensor):
    """
    (lat,lon) -> (y,x) N,2
    """
    r = 6378137.
    lon_rad = latlon[:,1] * torch.pi / 180.
    lat_rad = latlon[:,0] * torch.pi / 180.
    x = r * lon_rad
    y = r * torch.log(torch.tan(torch.pi / 4. + lat_rad / 2.))
    return torch.stack([y,x],dim=-1)

def mercator2lonlat(coord:torch.Tensor):
    """
    (y,x) -> (lat,lon) N,2
    """
    coord = torch.tensor(coord).to(torch.float64)
    r = 6378137.
    lon = (180. * coord[:,1]) / (torch.pi * r)
    lat = (2 * torch.atan(torch.exp(coord[:,0] / r)) - torch.pi * 0.5) * 180. / torch.pi
    return torch.stack([lat,lon],dim=-1)

def proj2photo(proj_coord:torch.Tensor,dem:torch.Tensor,rpc:RPCModelParameterTorch):
    lonlat_coord = mercator2lonlat(proj_coord)
    photo_coord = torch.stack(rpc.RPC_OBJ2PHOTO(lonlat_coord[:,0],lonlat_coord[:,1],dem),dim=1)
    return photo_coord

def bilinear_interpolate(array, points, use_cuda=False,device = None):
    """
    åœ¨çŸ©é˜µä¸Šè¿›è¡ŒåŒçº¿æ€§æ’å€¼é‡‡æ ·ï¼Œå¯é€‰æ‹©åœ¨ CPU (NumPy) æˆ– GPU (PyTorch) ä¸Šè¿è¡Œã€‚

    è¾“å…¥:
    - array: äºŒç»´ (H, W) æˆ–ä¸‰ç»´ (H, W, C) çš„ numpy æ•°ç»„æˆ– torch å¼ é‡ã€‚
    - points: (N, 2) çš„æµ®ç‚¹åæ ‡æ•°ç»„æˆ–å¼ é‡ï¼Œæ¯è¡Œè¡¨ç¤ºä¸€ä¸ªåæ ‡ [x, y]ã€‚
    - use_cuda:å¸ƒå°”å€¼ã€‚å¦‚æœä¸º Trueï¼Œåˆ™å°è¯•ä½¿ç”¨ GPU (CUDA) åŠ é€Ÿã€‚

    è¾“å‡º:
    - æ’å€¼ç»“æœï¼Œå½¢çŠ¶ä¸º (N,) æˆ– (N, C) çš„ numpy æ•°ç»„ã€‚
    """
    if device is None:
        device = 'cuda'
    # ----------- GPU (CUDA) åŠ é€Ÿè·¯å¾„ -----------
    if use_cuda:
        # æ£€æŸ¥ CUDA æ˜¯å¦å¯ç”¨ï¼Œå¦‚æœä¸å¯ç”¨åˆ™è­¦å‘Šå¹¶å›é€€åˆ° CPU
        if not torch.cuda.is_available():
            print("è­¦å‘Šï¼šCUDA ä¸å¯ç”¨ã€‚å°†å›é€€åˆ° CPU (NumPy) æ‰§è¡Œã€‚")
            use_cuda = False
        else:
            device = torch.device(device)
            
            # ç¡®ä¿è¾“å…¥æ˜¯ PyTorch å¼ é‡å¹¶ç§»è‡³ GPU
            # ä½¿ç”¨ torch.as_tensor é¿å…ä¸å¿…è¦çš„æ•°æ®æ‹·è´
            arr_tensor = torch.as_tensor(array, dtype=torch.float32, device=device)
            pts_tensor = torch.as_tensor(points, dtype=torch.float32, device=device)
            
            # å°†äºŒç»´æ•°ç»„æ‰©å±•ä¸º (H, W, 1) ä»¥ç»Ÿä¸€å¤„ç†
            if arr_tensor.dim() == 2:
                arr_tensor = arr_tensor.unsqueeze(-1)
            
            H, W, C = arr_tensor.shape
            x = pts_tensor[:, 0]
            y = pts_tensor[:, 1]
            
            # è®¡ç®—æ•´æ•°åæ ‡å¹¶çº¦æŸè¾¹ç•Œ
            # torch.floor çš„ç»“æœæ˜¯æµ®ç‚¹æ•°ï¼Œéœ€è¦è½¬ä¸ºé•¿æ•´å‹ç”¨äºç´¢å¼•
            x0 = torch.floor(x).long()
            y0 = torch.floor(y).long()
            
            # ä½¿ç”¨ torch.clamp çº¦æŸè¾¹ç•Œï¼Œç­‰åŒäº np.clip
            x1 = torch.clamp(x0 + 1, 0, W - 1)
            x0 = torch.clamp(x0, 0, W - 1)
            y1 = torch.clamp(y0 + 1, 0, H - 1)
            y0 = torch.clamp(y0, 0, H - 1)
            
            # æå–å››ä¸ªè§’ç‚¹çš„å€¼ï¼Œå½¢çŠ¶ (N, C)
            # PyTorch çš„é«˜çº§ç´¢å¼•æ–¹å¼ä¸ NumPy ç›¸åŒ
            Ia = arr_tensor[y0, x0, :]
            Ib = arr_tensor[y1, x0, :]
            Ic = arr_tensor[y0, x1, :]
            Id = arr_tensor[y1, x1, :]
            
            # è®¡ç®—æƒé‡ (dx, dy ä»ç„¶æ˜¯æµ®ç‚¹æ•°)
            dx = x - x0.float()
            dy = y - y0.float()
            
            wa = (1 - dx) * (1 - dy)
            wb = (1 - dx) * dy
            wc = dx * (1 - dy)
            wd = dx * dy
            
            # åŠ æƒæ±‚å’Œ (ä½¿ç”¨ unsqueeze(1) å¹¿æ’­åˆ°æ‰€æœ‰é€šé“)
            # wa[:, None] åœ¨ PyTorch ä¸­æ˜¯ wa.unsqueeze(1)
            result_tensor = (
                wa.unsqueeze(1) * Ia +
                wb.unsqueeze(1) * Ib +
                wc.unsqueeze(1) * Ic +
                wd.unsqueeze(1) * Id
            )
            
            # å‹ç¼©å¤šä½™çš„ç»´åº¦
            if arr_tensor.shape[-1] == 1 and arr_tensor.dim() == 3:
                result_tensor = result_tensor.squeeze(axis=1)
                
            # å°†ç»“æœä» GPU ç§»å› CPU å¹¶è½¬æ¢ä¸º NumPy æ•°ç»„
            return result_tensor.cpu().numpy()

    # ----------- CPU (NumPy) åŸå§‹è·¯å¾„ -----------
    # å¦‚æœ use_cuda ä¸º Falseï¼Œåˆ™æ‰§è¡ŒåŸå§‹é€»è¾‘
    array = np.asarray(array)
    points = np.asarray(points)
    
    # è®°å½•åŸå§‹ç»´åº¦ä»¥å†³å®šæœ€ç»ˆè¾“å‡ºå½¢çŠ¶
    original_ndim = array.ndim
    
    if array.ndim == 2:
        array = array[..., np.newaxis]
    
    H, W, C = array.shape
    x = points[:, 0].astype(float)
    y = points[:, 1].astype(float)
    
    x0 = np.floor(x).astype(int)
    x1 = np.clip(x0 + 1, 0, W - 1)
    x0 = np.clip(x0, 0, W - 1)
    
    y0 = np.floor(y).astype(int)
    y1 = np.clip(y0 + 1, 0, H - 1)
    y0 = np.clip(y0, 0, H - 1)
    
    Ia = array[y0, x0, :]
    Ib = array[y1, x0, :]
    Ic = array[y0, x1, :]
    Id = array[y1, x1, :]
    
    dx = x - x0
    dy = y - y0
    wa = (1 - dx) * (1 - dy)
    wb = (1 - dx) * dy
    wc = dx * (1 - dy)
    wd = dx * dy
    
    result = (
        wa[:, None] * Ia +
        wb[:, None] * Ib +
        wc[:, None] * Ic +
        wd[:, None] * Id
    )
    
    if original_ndim == 2:
        result = result.squeeze(axis=1)
    
    return result

def downsample_average(
    input_tensor: torch.Tensor,
    downsample_factor: int,
    use_cuda: bool = False,
    device = 'cuda'
) -> torch.Tensor:
    """
    ä½¿ç”¨æ»‘åŠ¨çª—å£å¹³å‡å€¼å¯¹å›¾åƒå¼ é‡è¿›è¡Œä¸‹é‡‡æ ·ã€‚

    è¯¥å‡½æ•°æ¥å—ä¸€ä¸ªå½¢çŠ¶ä¸º (H, W) æˆ– (H, W, C) çš„ PyTorch å›¾åƒå¼ é‡ï¼Œ
    å¹¶ä½¿ç”¨ä¸€ä¸ª (downsample_factor x downsample_factor) çš„çª—å£
    ä»¥ downsample_factor ä¸ºæ­¥é•¿è¿›è¡Œä¸é‡å çš„æ»‘åŠ¨çª—å£ä¸‹é‡‡æ ·ï¼Œ
    å¹¶å–çª—å£å†…çš„åƒç´ å¹³å‡å€¼ã€‚

    Args:
        input_tensor (torch.Tensor): è¾“å…¥çš„å›¾åƒå¼ é‡ï¼Œå½¢çŠ¶å¯ä»¥æ˜¯ (H, W) [ç°åº¦å›¾]
                                     æˆ– (H, W, C) [å½©è‰²å›¾]ã€‚
        downsample_factor (int): ä¸‹é‡‡æ ·å› å­ï¼Œå°†ä½œä¸ºçª—å£å¤§å°å’Œæ­¥é•¿ã€‚ä¾‹å¦‚ï¼Œ8 è¡¨ç¤º
                                 ä½¿ç”¨ 8x8 çš„çª—å£ä¸‹é‡‡æ ·8å€ã€‚
        use_cuda (bool, optional): å¦‚æœä¸º Trueï¼Œåˆ™å°è¯•ä½¿ç”¨ CUDA GPU è¿›è¡ŒåŠ é€Ÿã€‚
                                   å¦‚æœ CUDA ä¸å¯ç”¨ï¼Œå°†æ‰“å°è­¦å‘Šå¹¶å›é€€åˆ° CPUã€‚
                                   é»˜è®¤ä¸º Falseã€‚

    Returns:
        torch.Tensor: ç»è¿‡ä¸‹é‡‡æ ·åçš„å›¾åƒå¼ é‡ã€‚
                      å¦‚æœè¾“å…¥æ˜¯ (H, W)ï¼Œè¾“å‡ºæ˜¯ (H/factor, W/factor)ã€‚
                      å¦‚æœè¾“å…¥æ˜¯ (H, W, C)ï¼Œè¾“å‡ºæ˜¯ (H/factor, W/factor, C)ã€‚
                      è¾“å‡ºå¼ é‡å°†ä½äºè®¡ç®—æ‰€ç”¨çš„è®¾å¤‡ä¸Šï¼ˆCPU æˆ– CUDAï¼‰ã€‚

    Raises:
        ValueError: å¦‚æœè¾“å…¥å¼ é‡çš„ç»´åº¦ä¸æ˜¯ 2 æˆ– 3ã€‚
        TypeError: å¦‚æœè¾“å…¥ä¸æ˜¯ä¸€ä¸ª torch.Tensorã€‚
    """
    if not isinstance(input_tensor, torch.Tensor):
        raise TypeError(f"è¾“å…¥å¿…é¡»æ˜¯ torch.Tensorï¼Œä½†å¾—åˆ°çš„æ˜¯ {type(input_tensor)}")

    # --- 1. æ£€æŸ¥å’Œè®¾ç½®è®¡ç®—è®¾å¤‡ (CPU or CUDA) ---
    if use_cuda:
        if torch.cuda.is_available():
            device = torch.device(device)
            # print("CUDA is available. Using GPU for acceleration.")
        else:
            device = torch.device('cpu')
            print("è­¦å‘Š: è¯·æ±‚ä½¿ç”¨ CUDAï¼Œä½† CUDA ä¸å¯ç”¨ã€‚å°†å›é€€åˆ° CPUã€‚")
    else:
        device = torch.device('cpu')

    # å°†è¾“å…¥å¼ é‡ç§»åŠ¨åˆ°ç›®æ ‡è®¾å¤‡
    input_tensor = input_tensor.to(device)

    # --- 2. é¢„å¤„ç†ï¼šå°†è¾“å…¥å¼ é‡è°ƒæ•´ä¸º PyTorch å·ç§¯å±‚æœŸæœ›çš„æ ¼å¼ (N, C, H, W) ---
    # PyTorch çš„ 2D å·ç§¯/æ± åŒ–å±‚éœ€è¦ä¸€ä¸ª4Då¼ é‡ä½œä¸ºè¾“å…¥ï¼š(æ‰¹é‡å¤§å°, é€šé“æ•°, é«˜, å®½)
    input_dim = input_tensor.dim()
    if input_dim == 2:  # ç°åº¦å›¾ (H, W)
        is_grayscale = True
        # æ‰©å±•ä¸º (1, 1, H, W)
        tensor_in = input_tensor.unsqueeze(0).unsqueeze(0)
    elif input_dim == 3:  # å½©è‰²å›¾ (H, W, C)
        is_grayscale = False
        # PyTorch ä½¿ç”¨ "channels-first" (C, H, W) æ ¼å¼ï¼Œæ‰€ä»¥éœ€è¦è½¬æ¢ç»´åº¦
        # (H, W, C) -> (C, H, W)ï¼Œç„¶åæ‰©å±•ä¸º (1, C, H, W)
        tensor_in = input_tensor.permute(2, 0, 1).unsqueeze(0)
    else:
        raise ValueError(f"è¾“å…¥å¼ é‡çš„ç»´åº¦å¿…é¡»æ˜¯ 2 (H,W) æˆ– 3 (H,W,C)ï¼Œä½†å¾—åˆ°çš„æ˜¯ {input_dim}")

    # ç¡®ä¿è¾“å…¥å¼ é‡æ˜¯æµ®ç‚¹æ•°ç±»å‹ï¼Œä»¥ä¾¿è®¡ç®—å¹³å‡å€¼
    tensor_in = tensor_in.float()

    # --- 3. å®šä¹‰å¹¶æ‰§è¡Œå¹³å‡æ± åŒ–æ“ä½œ ---
    # ä½¿ç”¨ AvgPool2d å¯ä»¥é«˜æ•ˆåœ°å®Œæˆæ»‘åŠ¨çª—å£å¹³å‡æ“ä½œ
    # kernel_size æ˜¯çª—å£å¤§å°
    # stride æ˜¯æ»‘åŠ¨æ­¥é•¿
    # å½“ kernel_size å’Œ stride ç›¸åŒæ—¶ï¼Œçª—å£ä¸ä¼šé‡å 
    pool = nn.AvgPool2d(kernel_size=downsample_factor, stride=downsample_factor).to(device)
    downsampled_tensor = pool(tensor_in)

    # --- 4. åå¤„ç†ï¼šå°†è¾“å‡ºå¼ é‡æ¢å¤ä¸ºåŸå§‹æ ¼å¼ ---
    if is_grayscale:
        # (1, 1, H', W') -> (H', W')
        output_tensor = downsampled_tensor.squeeze(0).squeeze(0)
    else:
        # (1, C, H', W') -> (C, H', W') -> (H', W', C)
        output_tensor = downsampled_tensor.squeeze(0).permute(1, 2, 0)

    return output_tensor.cpu()

def downsample(arr:torch.Tensor,ds,use_cuda=False,show_detail=False,mode='mid',device = None):
    """
    mode: mid or avg
    """
    if ds <= 0:
        return arr
    # if len(arr.shape) < 4:
    #     arr = arr.unsqueeze(-1)
    arr_ds = []
    if show_detail:
        pbar = tqdm(total = len(arr))
    if device is None:
        device = 'cuda'
    for a in arr:
        if mode == 'mid':
            if len(a.shape) < 3:
                a = a.unsqueeze(-1)
            H,W = a.shape[:2]
            lines = np.arange(0,H - ds + 1,ds) + (ds - 1.) * 0.5
            samps = np.arange(0,W - ds + 1,ds) + (ds - 1.) * 0.5
            sample_idxs = np.stack(np.meshgrid(samps,lines,indexing='xy'),axis=-1).reshape(-1,2) # x,y
            a = torch.tensor(bilinear_interpolate(a,sample_idxs,use_cuda=use_cuda))
            arr_ds.append(a.reshape(len(lines),len(samps),-1).squeeze())
        elif mode == 'avg':
            a_ds = downsample_average(a,ds,use_cuda)
            arr_ds.append(a_ds)
        else:
            raise ValueError("downsample mode should either be mid or avg")
        if show_detail:
            pbar.update(1)
    arr_ds = torch.stack(arr_ds,dim=0)
    return arr_ds

def print_hwc_matrix(matrix: np.ndarray, precision:int = 2):
    """
    å°†ä¸€ä¸ªå½¢çŠ¶ä¸º (H, W, C) çš„ NumPy æ•°ç»„åœ¨ç»ˆç«¯ä¸­ä»¥ H*W çŸ©é˜µçš„æ ¼å¼æ‰“å°å‡ºæ¥ã€‚
    å¢åŠ äº†å¯¹æµ®ç‚¹æ•°æ ¼å¼åŒ–çš„æ”¯æŒã€‚

    Args:
        matrix (np.ndarray): ä¸€ä¸ªä¸‰ç»´çš„ NumPy æ•°ç»„ï¼Œå½¢çŠ¶ä¸º (H, W, C)ã€‚
        precision (Optional[int], optional): 
            å½“æ•°ç»„æ˜¯æµ®ç‚¹ç±»å‹æ—¶ï¼ŒæŒ‡å®šè¦ä¿ç•™çš„å°æ•°ä½æ•°ã€‚
            å¦‚æœä¸º Noneï¼Œåˆ™ä½¿ç”¨é»˜è®¤çš„å­—ç¬¦ä¸²è¡¨ç¤ºã€‚é»˜è®¤ä¸º Noneã€‚
    """
    # æ£€æŸ¥è¾“å…¥æ˜¯å¦ä¸ºä¸‰ç»´ NumPy æ•°ç»„
    if not isinstance(matrix, np.ndarray) or matrix.ndim != 3:
        print("é”™è¯¯ï¼šè¾“å…¥å¿…é¡»æ˜¯ä¸€ä¸ªä¸‰ç»´çš„ NumPy æ•°ç»„ (H, W, C)ã€‚")
        return

    # è·å–æ•°ç»„çš„ç»´åº¦
    H, W, C = matrix.shape

    # å¦‚æœæ•°ç»„ä¸ºç©ºï¼Œåˆ™ä¸æ‰“å°
    if H == 0 or W == 0:
        print("[]")
        return
    
    string_elements = []
    for h in range(H):
        row_elements = []
        for w in range(W):
            vector = matrix[h, w]
            string_element = ""
            if precision is not None:
                # å¦‚æœæŒ‡å®šäº†ç²¾åº¦ï¼Œå¯¹å‘é‡ä¸­çš„æ¯ä¸ªæ•°å­—è¿›è¡Œæ ¼å¼åŒ–
                try:
                    # ä½¿ç”¨ f-string çš„åµŒå¥—æ ¼å¼åŒ–åŠŸèƒ½
                    formatted_numbers = [f"{num:.{precision}f}" for num in vector]
                    string_element = f"[{' '.join(formatted_numbers)}]"
                except (ValueError, TypeError):
                    # å¦‚æœæ ¼å¼åŒ–å¤±è´¥ï¼ˆä¾‹å¦‚ï¼Œæ•°ç»„ä¸æ˜¯æ•°å­—ç±»å‹ï¼‰ï¼Œåˆ™é€€å›é»˜è®¤æ–¹å¼
                    string_element = str(vector)
            else:
                # æœªæŒ‡å®šç²¾åº¦ï¼Œä½¿ç”¨ NumPy é»˜è®¤çš„å­—ç¬¦ä¸²è½¬æ¢
                string_element = str(vector)
            
            row_elements.append(string_element)
        string_elements.append(row_elements)

    # æ‰¾åˆ°æ‰€æœ‰å­—ç¬¦ä¸²åŒ–åçš„å…ƒç´ ä¸­çš„æœ€å¤§é•¿åº¦ï¼Œç”¨äºå¯¹é½
    max_len = max([len(s) for row in string_elements for s in row] or [0])

    # æ‰“å°å¸¦è¾¹æ¡†çš„çŸ©é˜µ
    print("â”Œ" + "â”€" * (W * (max_len + 2) - 2) + "â”")
    for row in string_elements:
        print("â”‚", end="")
        for element in row:
            # ä½¿ç”¨ ljust æ–¹æ³•å¡«å……ç©ºæ ¼ï¼Œä½¿æ¯ä¸ªå…ƒç´ å æ®ç›¸åŒçš„å®½åº¦
            print(f"{element:<{max_len}}", end="  ")
        print("â”‚")
    print("â””" + "â”€" * (W * (max_len + 2) - 2) + "â”˜")

def apply_polynomial(x, coefs):
    y = torch.zeros_like(x)
    for i, c in enumerate(coefs):
        y = y + c * (x ** (len(coefs) - 1 - i))
    return y

def get_map_coef(target:np.ndarray,bins=1000,deg=20):
    extend_bins = int(bins * 0.1)
    src = np.linspace(0,1,bins)
    tgt = np.quantile(target,src)
    tgt = np.concatenate([2 * tgt[0] - tgt[:extend_bins][::-1],tgt,2 * tgt[-1] - tgt[-extend_bins:][::-1]],axis=0)
    src = np.linspace(-1,1,bins + 2 * extend_bins)
    coefs = np.polyfit(src,tgt,deg = deg)
    return coefs

def resample_from_quad(
    source_image: np.ndarray,
    quad_coords: np.ndarray,
    target_shape: Tuple[int, int],
    tile_size: int = 4096,
    interpolation: int = cv2.INTER_LINEAR,
    border_mode: int = cv2.BORDER_REPLICATE
) -> Tuple[np.ndarray, np.ndarray]:
    """
    æ ¹æ®å››è¾¹å½¢è§’ç‚¹é‡é‡‡æ ·å›¾åƒï¼Œå¹¶è¿”å›åæ ‡æ˜ å°„ã€‚
    æ­¤æœ€ç»ˆç‰ˆæœ¬é€šè¿‡â€œç›®æ ‡åˆ†å—â€å’Œâ€œæºåŠ¨æ€è£å‰ªâ€è§£å†³äº†ç›®æ ‡å’Œæºå›¾åƒå‡å¯èƒ½è¶…å¤§å°ºå¯¸çš„é—®é¢˜ã€‚

    Args:
        source_image (np.ndarray): è¾“å…¥çš„æºå›¾åƒ (H, W) æˆ– (H, W, 3)ã€‚
        quad_coords (np.ndarray): å››è¾¹å½¢çš„å››ä¸ªè§’ç‚¹åæ ‡ (4, 2), (row, col)ã€‚
        target_shape (tuple[int, int]): ç›®æ ‡è¾“å‡ºå›¾åƒçš„å°ºå¯¸ (h, w)ã€‚
        tile_size (int, optional): åˆ†å—å¤„ç†çš„å—è¾¹é•¿ã€‚
        interpolation (int, optional): æ’å€¼æ–¹æ³•ã€‚
        border_mode (int, optional): è¾¹ç•Œæ¨¡å¼ã€‚

    Returns:
        tuple[np.ndarray, np.ndarray]: é‡é‡‡æ ·å›¾åƒå’Œåæ ‡æ˜ å°„ã€‚
    """
    # 1. è¾“å…¥éªŒè¯å’ŒçŸ©é˜µè®¡ç®— (ä¸ä¹‹å‰ç›¸åŒ)
    # ... (æ­¤å¤„çœç•¥äº†ä¸ä¸Šä¸€ç‰ˆç›¸åŒçš„éªŒè¯å’ŒçŸ©é˜µè®¡ç®—ä»£ç ï¼Œè¯·ç›´æ¥å¤åˆ¶è¿‡æ¥)
    if source_image.ndim not in [2, 3]:
        raise ValueError("è¾“å…¥å›¾åƒå¿…é¡»æ˜¯äºŒç»´ (ç°åº¦å›¾) æˆ–ä¸‰ç»´ (RGB/BGRå›¾) æ•°ç»„ã€‚")
    if quad_coords.shape != (4, 2):
        raise ValueError("è§’ç‚¹åæ ‡æ•°ç»„çš„å½¢çŠ¶å¿…é¡»æ˜¯ (4, 2)ã€‚")

    h, w = target_shape
    src_h, src_w = source_image.shape[:2]
    
    src_points = quad_coords[:, ::-1].astype(np.float32)
    dst_points = np.array([
        [0, 0], [w - 1, 0], [w - 1, h - 1], [0, h - 1]
    ], dtype=np.float32)

    M = cv2.getPerspectiveTransform(src_points, dst_points)
    try:
        M_inv = np.linalg.inv(M)
    except np.linalg.LinAlgError:
        print("é”™è¯¯: å˜æ¢çŸ©é˜µ M æ˜¯å¥‡å¼‚çŸ©é˜µï¼Œæ— æ³•è®¡ç®—é€†çŸ©é˜µã€‚")
        return None, None

    # 2. å‡†å¤‡ç©ºçš„è¾“å‡ºç”»å¸ƒ (ä¸ä¹‹å‰ç›¸åŒ)
    if source_image.ndim == 3:
        output_channels = source_image.shape[2]
        resampled_image = np.zeros((h, w, output_channels), dtype=source_image.dtype)
    else:
        resampled_image = np.zeros((h, w), dtype=source_image.dtype)
    
    coordinate_map = np.zeros((h, w, 2), dtype=np.float32)

    # 3. åˆ†å—å¤„ç†
    for y_start in range(0, h, tile_size):
        for x_start in range(0, w, tile_size):
            tile_h = min(tile_size, h - y_start)
            tile_w = min(tile_size, w - x_start)
            
            # a. ä¸ºå½“å‰å—åˆ›å»ºç›®æ ‡åæ ‡ç½‘æ ¼å¹¶å˜æ¢å›æºåæ ‡ç³»
            y_grid, x_grid = np.mgrid[y_start : y_start + tile_h, x_start : x_start + tile_w]
            target_coords_homo = np.stack((x_grid.ravel(), y_grid.ravel(), np.ones(tile_h * tile_w)), axis=1)
            source_coords_homo = target_coords_homo @ M_inv.T
            w_inv = 1.0 / (source_coords_homo[:, 2] + 1e-9)
            source_coords_xy = source_coords_homo[:, :2] * w_inv[:, np.newaxis]
            
            # b. è®¡ç®—æ‰€éœ€æºåŒºåŸŸçš„è¾¹ç•Œæ¡† (Bounding Box)
            # map1 æ˜¯ x åæ ‡ (col), map2 æ˜¯ y åæ ‡ (row)
            map1 = source_coords_xy[:, 0]
            map2 = source_coords_xy[:, 1]
            
            # è®¡ç®—è¾¹ç•Œå¹¶å¢åŠ ä¸€ç‚¹ paddingï¼Œä»¥é˜²æ’å€¼æ—¶è®¿é—®åˆ°è¾¹ç•Œå¤–
            padding = 2 
            src_x_min = max(0, int(np.floor(map1.min())) - padding)
            src_x_max = min(src_w, int(np.ceil(map1.max())) + padding)
            src_y_min = max(0, int(np.floor(map2.min())) - padding)
            src_y_max = min(src_h, int(np.ceil(map2.max())) + padding)

            # å¦‚æœæ‰€éœ€åŒºåŸŸå®Œå…¨åœ¨æºå›¾åƒå¤–ï¼Œåˆ™è·³è¿‡
            if src_x_min >= src_w or src_x_max <= 0 or src_y_min >= src_h or src_y_max <= 0:
                continue

            # c. è£å‰ªæºå›¾åƒROIå’Œè°ƒæ•´åæ ‡
            source_roi = source_image[src_y_min:src_y_max, src_x_min:src_x_max]
            
            # å°†ç»å¯¹åæ ‡è°ƒæ•´ä¸ºç›¸å¯¹äº ROI çš„åæ ‡
            adjusted_map1 = (map1 - src_x_min).reshape(tile_h, tile_w).astype(np.float32)
            adjusted_map2 = (map2 - src_y_min).reshape(tile_h, tile_w).astype(np.float32)

            # d. ä½¿ç”¨è£å‰ªåçš„ ROI å’Œè°ƒæ•´åçš„ map è°ƒç”¨ remap
            resampled_tile = cv2.remap(
                source_roi,         #  ä½¿ç”¨è£å‰ªåçš„å°å›¾
                adjusted_map1,      #  ä½¿ç”¨è°ƒæ•´åçš„åæ ‡
                adjusted_map2,      #  ä½¿ç”¨è°ƒæ•´åçš„åæ ‡
                interpolation=interpolation,
                borderMode=border_mode
            )
            
            # e. æ‹¼æ¥ç»“æœ
            resampled_image[y_start:y_start+tile_h, x_start:x_start+tile_w] = resampled_tile
            coordinate_map[y_start:y_start+tile_h, x_start:x_start+tile_w, 0] = map2.reshape(tile_h, tile_w)
            coordinate_map[y_start:y_start+tile_h, x_start:x_start+tile_w, 1] = map1.reshape(tile_h, tile_w)
            
    return resampled_image, coordinate_map

def vis_feat_pca(feat:np.ndarray,output_path = None):
    """
    feat shape:(H,W,C)
    """
    H,W,C = feat.shape
    feat = feat.reshape(-1,C)
    pca = PCA(n_components=3)
    feat = pca.fit_transform(feat)
    feat = 255. * (feat - feat.min()) / (feat.max() - feat.min())
    feat = feat.reshape(H,W,3).astype(np.uint8)
    if not output_path is None:
        cv2.imwrite(output_path,feat)
    else:
        return feat

def vis_feat_twin(feat1,feat2):
    H,W,C = feat1.shape
    # feat1 = feat1.permute(1,2,0).flatten(0,1).cpu().numpy()
    # feat2 = feat2.permute(1,2,0).flatten(0,1).cpu().numpy()
    feat1 = feat1.reshape(-1,C)
    feat2 = feat2.reshape(-1,C)
    feat = np.concatenate([feat1,feat2],axis=0)
    # tsne = TSNE(n_components=3, random_state=42,metric='cosine')
    # feat = tsne.fit_transform(feat)
    pca = PCA(n_components=3)
    
    feat = pca.fit_transform(feat)
    # feat = feat[:,:3]
    feat = (feat - feat.min()) / (feat.max() - feat.min())
    feat1 = feat[:H*W]
    feat2 = feat[H*W:]
    feat1 = feat1.reshape(H,W,3)
    feat2 = feat2.reshape(H,W,3)
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))

    # åœ¨ç¬¬ä¸€ä¸ªå­å›¾ä¸­æ˜¾ç¤ºç¬¬ä¸€å¼ å›¾ç‰‡
    ax1.imshow(feat1)
    ax1.axis('off')  # å…³é—­åæ ‡è½´
    ax1.set_title('Image 1')

    # åœ¨ç¬¬äºŒä¸ªå­å›¾ä¸­æ˜¾ç¤ºç¬¬äºŒå¼ å›¾ç‰‡
    ax2.imshow(feat2)
    ax2.axis('off')  # å…³é—­åæ ‡è½´
    ax2.set_title('Image 2')

    # è°ƒæ•´å¸ƒå±€
    plt.tight_layout()
    fig.canvas.draw()
    width, height = fig.canvas.get_width_height()
    image_buffer = fig.canvas.buffer_rgba()
    image_array = np.frombuffer(image_buffer, dtype=np.uint8)
    image_array = image_array.reshape(height, width, 4)[...,:3]

    return image_array
    
def vis_conf(conf:np.ndarray,img:np.ndarray,ds,div = .5,output_path = None):
    points = (get_coord_mat(conf.shape[0],conf.shape[1]) * ds + ds * .5).reshape(-1,2)
    scores = conf.reshape(-1)
    canvas_cont = img.copy()
    canvas_div = img.copy()

    def score_to_color_cont(score):
        red = int((1 - score) * 255)
        green = int(score * 255)
        return (red , green, 0)
    
    def score_to_color_div(score,div):
        if score >= div:
            return (0,255,0)
        else:
            return (255,0,0)
    
    for p,score in zip(points,scores):
        p = p.astype(int)
        color_cont = score_to_color_cont(score)
        color_div = score_to_color_div(score,div)

        # debug_print(f"{canvas_cont.shape}\t{canvas_cont.dtype}\t{p}")

        cv2.circle(canvas_cont,(p[1],p[0]),radius=1,color=color_cont,thickness=-1)
        cv2.circle(canvas_div,(p[1],p[0]),radius=1,color=color_div,thickness=-1)
    
    if not output_path is None:
        cv2.imwrite(output_path.replace('.png','_cont.png'),cv2.cvtColor(canvas_cont,cv2.COLOR_RGB2BGR))
        cv2.imwrite(output_path.replace('.png','_div.png'),cv2.cvtColor(canvas_div,cv2.COLOR_RGB2BGR))
    else:
        return canvas_cont,canvas_div

def visualize_subset_points(points1, points2, output_path, padding=50, point_radius=5):
    # å°†ä¸¤ç»„ç‚¹åˆå¹¶ï¼Œä»¥ç¡®å®šç”»å¸ƒçš„æ•´ä½“å°ºå¯¸
    all_points = np.vstack((points1, points2)) if points1.size > 0 and points2.size > 0 else \
                points1 if points1.size > 0 else points2

    min_x = np.min(all_points[:, 0])
    min_y = np.min(all_points[:, 1])

    # è®¡ç®—æ‰€æœ‰ç‚¹çš„æœ€å¤§ x å’Œ y åæ ‡
    max_x = np.max(all_points[:, 0]) - min_x
    max_y = np.max(all_points[:, 1]) - min_y

    points1[:,0] -= min_x
    points1[:,1] -= min_y
    points2[:,0] -= min_x
    points2[:,1] -= min_y
    
    

    # æ ¹æ®æœ€å¤§åæ ‡å’Œè¾¹è·è®¡ç®—ç”»å¸ƒå°ºå¯¸
    canvas_width = int(max_x + padding * 2)
    canvas_height = int(max_y + padding * 2)

    # åˆ›å»ºä¸€ä¸ªç™½è‰²ç”»å¸ƒ (BGR æ ¼å¼)
    # np.ones åˆ›å»ºä¸€ä¸ªæµ®ç‚¹æ•°æ•°ç»„ï¼Œä¹˜ä»¥ 255ï¼Œç„¶åè½¬æ¢ä¸º uint8 ç±»å‹
    canvas = np.ones((canvas_height, canvas_width, 3), dtype=np.uint8) * 255

    # å®šä¹‰é¢œè‰² (OpenCV ä½¿ç”¨ BGR é¡ºåº)
    green_color = (0, 255, 0)
    red_color = (0, 0, 255)

    # ç»˜åˆ¶ç¬¬äºŒç»„ç‚¹ï¼ˆçº¢è‰²ï¼‰
    for point in points2:
        # å°†åæ ‡è½¬æ¢ä¸ºæ•´æ•°å…ƒç»„ï¼Œå¹¶åŠ ä¸Šè¾¹è·
        center = (int(point[1]) + padding, int(point[0]) + padding)
        cv2.circle(canvas, center, point_radius, red_color, thickness=-1)

    # ç»˜åˆ¶ç¬¬ä¸€ç»„ç‚¹ï¼ˆç»¿è‰²ï¼‰
    for point in points1:
        # å°†åæ ‡è½¬æ¢ä¸ºæ•´æ•°å…ƒç»„ï¼Œå¹¶åŠ ä¸Šè¾¹è·
        center = (int(point[1]) + padding, int(point[0]) + padding)
        cv2.circle(canvas, center, point_radius, green_color, thickness=-1) # thickness=-1 è¡¨ç¤ºå®å¿ƒåœ†

    

    # ä¿å­˜å›¾åƒåˆ°æŒ‡å®šè·¯å¾„
    cv2.imwrite(output_path, canvas)

def visualize_feature_correspondences(
    feature_map1: np.ndarray,
    feature_map2: np.ndarray,
    points1: np.ndarray,
    points2: np.ndarray,
    draw_lines: bool = True
) -> np.ndarray:
    """
    å°†ä¸¤ä¸ªç‰¹å¾å›¾åŠå…¶å¯¹åº”ç‚¹è¿›è¡Œå¯è§†åŒ–ã€‚

    è¯¥å‡½æ•°é€šè¿‡è”åˆPCAå°†ç‰¹å¾å›¾é™ç»´å¹¶å½’ä¸€åŒ–åˆ°RGBç©ºé—´ï¼Œç„¶åå¹¶æ’ç»˜åˆ¶å®ƒä»¬ã€‚
    å¯¹åº”ç‚¹ä¼šç”¨ç›¸åŒçš„é¢œè‰²åœ¨ä¸¤å¼ å›¾ä¸Šæ ‡è®°å‡ºæ¥ï¼Œä»¥ä¾¿äºæ¯”è¾ƒç‰¹å¾çš„ç›¸ä¼¼æ€§ã€‚

    Args:
        feature_map1 (np.ndarray): ç¬¬ä¸€ä¸ªç‰¹å¾å›¾ï¼Œå½¢çŠ¶ä¸º (H, W, D)ã€‚
        feature_map2 (np.ndarray): ç¬¬äºŒä¸ªç‰¹å¾å›¾ï¼Œå½¢çŠ¶ä¸º (H, W, D)ã€‚
        points1 (np.ndarray): ç¬¬ä¸€ä¸ªç‰¹å¾å›¾ä¸Šçš„å¯¹åº”ç‚¹åæ ‡ï¼Œå½¢çŠ¶ä¸º (N, 2)ï¼Œæ ¼å¼ä¸º (x, y)ã€‚
        points2 (np.ndarray): ç¬¬äºŒä¸ªç‰¹å¾å›¾ä¸Šçš„å¯¹åº”ç‚¹åæ ‡ï¼Œå½¢çŠ¶ä¸º (N, 2)ï¼Œæ ¼å¼ä¸º (x, y)ã€‚
        draw_lines (bool): æ˜¯å¦åœ¨å¯¹åº”ç‚¹ä¹‹é—´ç»˜åˆ¶è¿æ¥çº¿ï¼Œé»˜è®¤ä¸º Trueã€‚

    Returns:
        np.ndarray: ä¸€ä¸ªåŒ…å«æœ€ç»ˆå¯è§†åŒ–ç»“æœçš„RGBå›¾åƒçš„NumPyæ•°ç»„ã€‚
    """
    # --- 1. è¾“å…¥éªŒè¯ ---
    if not (isinstance(feature_map1, np.ndarray) and isinstance(feature_map2, np.ndarray) and
            isinstance(points1, np.ndarray) and isinstance(points2, np.ndarray)):
        raise TypeError("æ‰€æœ‰è¾“å…¥éƒ½å¿…é¡»æ˜¯NumPyæ•°ç»„ã€‚")
        
    if feature_map1.shape[:2] != feature_map2.shape[:2]:
        raise ValueError("ä¸¤ä¸ªç‰¹å¾å›¾çš„é«˜åº¦ï¼ˆHï¼‰å’Œå®½åº¦ï¼ˆWï¼‰å¿…é¡»ç›¸åŒã€‚")
    if feature_map1.shape[2] != feature_map2.shape[2]:
        raise ValueError("ä¸¤ä¸ªç‰¹å¾å›¾çš„ç‰¹å¾ç»´åº¦ï¼ˆDï¼‰å¿…é¡»ç›¸åŒã€‚")
    if points1.shape != points2.shape:
        raise ValueError("ä¸¤ç»„å¯¹åº”ç‚¹çš„æ•°é‡å’Œç»´åº¦å¿…é¡»ç›¸åŒã€‚")
    if points1.ndim != 2 or points1.shape[1] != 2:
        raise ValueError("åæ ‡ç‚¹æ•°ç»„çš„å½¢çŠ¶å¿…é¡»æ˜¯ (N, 2)ã€‚")

    H, W, D = feature_map1.shape
    N = points1.shape[0]

    # --- 2. è”åˆPCAé™ç»´ä¸å½’ä¸€åŒ– ---
    # ä¸ºäº†å…¬å¹³æ¯”è¾ƒï¼Œæˆ‘ä»¬å°†ä¸¤ä¸ªç‰¹å¾å›¾çš„æ•°æ®åˆå¹¶åœ¨ä¸€èµ·è¿›è¡ŒPCAå’Œç¼©æ”¾
    fm1_reshaped = feature_map1.reshape((H * W, D))
    fm2_reshaped = feature_map2.reshape((H * W, D))
    all_features = np.concatenate([fm1_reshaped, fm2_reshaped], axis=0)

    # åº”ç”¨PCAå°†ç‰¹å¾é™åˆ°3ç»´
    pca = PCA(n_components=3)
    features_pca = pca.fit_transform(all_features)

    # # ä½¿ç”¨MinMaxScalerå°†PCAç»“æœå½’ä¸€åŒ–åˆ°[0, 1]èŒƒå›´ï¼Œä»¥ä¾¿æ˜¾ç¤ºä¸ºRGBé¢œè‰²
    # scaler = MinMaxScaler(feature_range=(1e-6, 1. - 1e-6))
    # features_normalized = scaler.fit_transform(features_pca)
    features_normalized = (features_pca - features_pca.min()) / (features_pca.max() - features_pca.min() + 1e-9)

    # å°†å¤„ç†åçš„æ•°æ®åˆ†ç¦»å¹¶é‡å¡‘ä¸ºä¸¤ä¸ªRGBå›¾åƒ
    img1_rgb = features_normalized[:H * W, :].reshape((H, W, 3))
    img2_rgb = features_normalized[H * W:, :].reshape((H, W, 3))

    # --- 3. ä½¿ç”¨Matplotlibè¿›è¡Œç»˜å›¾ ---
    # æ ¹æ®å›¾åƒçš„å®½é«˜æ¯”åŠ¨æ€è®¡ç®—ç”»å¸ƒå¤§å°
    fig_w = 12
    fig_h = fig_w * H / (W * 2) if W > 0 else 6
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(fig_w, fig_h), dpi=150)
    fig.tight_layout(pad=3.0)

    # æ˜¾ç¤ºä¸¤ä¸ªé™ç»´åçš„ç‰¹å¾å›¾
    ax1.imshow(img1_rgb)
    ax1.axis('off')

    ax2.imshow(img2_rgb)
    ax2.axis('off')

    # --- 4. ç»˜åˆ¶å¯¹åº”ç‚¹å’Œè¿æ¥çº¿ ---
    if N > 0:
        # **ä¿®æ”¹åçš„é€»è¾‘**:
        # 1. ä»é™ç»´åçš„RGBå›¾åƒä¸­ç›´æ¥é‡‡æ ·ï¼Œä½œä¸ºç‚¹çš„é¢œè‰²
        # 2. ä¿ç•™ç‹¬ç«‹çš„é¢œè‰²æ˜ å°„(jet)ï¼Œä»…ç”¨äºç»˜åˆ¶è¿æ¥çº¿ï¼Œä»¥å”¯ä¸€æ ‡è¯†åŒ¹é…å¯¹

        # å°†æµ®ç‚¹åæ ‡è½¬æ¢ä¸ºæ•´æ•°ç´¢å¼•ç”¨äºé¢œè‰²é‡‡æ ·
        # æ³¨æ„ï¼šnumpyç´¢å¼•æ˜¯(è¡Œ, åˆ—)ï¼Œå¯¹åº”äº(y, x)
        points1_idx = np.round(points1).astype(int)
        points2_idx = np.round(points2).astype(int)
        
        # è£å‰ªç´¢å¼•ä»¥ç¡®ä¿å®ƒä»¬åœ¨å›¾åƒè¾¹ç•Œå†…
        points1_idx[:, 0] = np.clip(points1_idx[:, 0], 0, W - 1)
        points1_idx[:, 1] = np.clip(points1_idx[:, 1], 0, H - 1)
        points2_idx[:, 0] = np.clip(points2_idx[:, 0], 0, W - 1)
        points2_idx[:, 1] = np.clip(points2_idx[:, 1], 0, H - 1)

        # åœ¨å¯¹åº”ç‚¹ä½ç½®é‡‡æ ·RGBé¢œè‰²
        point_colors1 = img1_rgb[points1_idx[:, 1], points1_idx[:, 0]]
        point_colors2 = img2_rgb[points2_idx[:, 1], points2_idx[:, 0]]
        
        # åœ¨ä¸¤å¼ å›¾ä¸Šåˆ†åˆ«ç»˜åˆ¶ç‚¹ï¼Œç‚¹çš„é¢œè‰²æ˜¯å…¶èƒŒæ™¯ç‰¹å¾çš„é¢œè‰²
        # sæ˜¯ç‚¹çš„å¤§å°, edgecolorä½¿å…¶åœ¨å„ç§èƒŒæ™¯ä¸‹éƒ½å¯è§
        ax1.scatter(points1[:, 0], points1[:, 1], c=point_colors1, s=25, edgecolor='white', linewidth=1.0, zorder=3)
        ax2.scatter(points2[:, 0], points2[:, 1], c=point_colors2, s=25, edgecolor='white', linewidth=1.0, zorder=3)

        # (å¯é€‰) åœ¨å¯¹åº”ç‚¹ä¹‹é—´ç»˜åˆ¶è¿æ¥çº¿
        if draw_lines:
            # ç”Ÿæˆ N ä¸ªç‹¬ç‰¹çš„é¢œè‰²ï¼Œä¸“é—¨ç”¨äºè¿æ¥çº¿ï¼Œä»¥ä¾¿å”¯ä¸€æ ‡è¯†åŒ¹é…å¯¹
            line_cmap = plt.get_cmap('jet')
            line_colors = line_cmap(np.linspace(0, 1, N))
            for i in range(N):
                con = ConnectionPatch(
                    xyA=points2[i], xyB=points1[i],
                    coordsA=ax2.transData, coordsB=ax1.transData,
                    axesA=ax2, axesB=ax1,
                    color=line_colors[i], linewidth=1.2,
                    linestyle='dashed', zorder=2
                )
                fig.add_artist(con)

    # --- 5. å°†ç”»å¸ƒè½¬æ¢ä¸ºNumPyæ•°ç»„ ---
    fig.canvas.draw()
    # ä»bufferä¸­è·å–RGBæ•°æ®
    width, height = fig.canvas.get_width_height()
    img_array = np.frombuffer(fig.canvas.tostring_argb(), dtype=np.uint8).reshape((height, width, 4))[:,:,1:]

    # å…³é—­å›¾å½¢ï¼Œé˜²æ­¢åœ¨Jupyterç­‰ç¯å¢ƒä¸­è‡ªåŠ¨æ˜¾ç¤º
    plt.close(fig)

    return img_array

def visualize_obj_error(obj_P2: np.ndarray, pred_P2: np.ndarray, canvas_size: tuple = (800, 800), sample_k: int = 1000, ranges = None):
    """
    å¯è§†åŒ–åæ ‡å›å½’çš„è¯¯å·®ï¼Œç”Ÿæˆä¸‰ç§åˆ†æå›¾åƒã€‚

    Args:
        obj_P2 (np.ndarray): çœŸå®çš„åæ ‡æ•°ç»„, shape=(N, 2)ã€‚
        pred_P2 (np.ndarray): é¢„æµ‹çš„åæ ‡æ•°ç»„, shape=(N, 2)ã€‚
        canvas_size (tuple): è¾“å‡ºå›¾åƒçš„å°ºå¯¸ã€‚
        sample_k (int): ä¸ºäº†é¿å…å›¾åƒè¿‡äºæ‚ä¹±ï¼Œéšæœºé‡‡æ ·çš„ç‚¹çš„æ•°é‡ã€‚

    Returns:
        dict: ä¸€ä¸ªåŒ…å«ä¸‰ç§å¯è§†åŒ–å›¾åƒ (numpy æ•°ç»„) çš„å­—å…¸ã€‚
              {'quiver': quiver_plot, 'heatmap': error_heatmap, 'histogram': error_histogram}
    """
    def fig_to_numpy(fig: plt.Figure) -> np.ndarray:
        """
        ä¸€ä¸ªæ›´ç¨³å®šå’Œé«˜æ•ˆçš„ Matplotlib Figure è½¬ NumPy æ•°ç»„çš„å‡½æ•°ã€‚
        å®ƒç›´æ¥ä» canvas ç¼“å†²åŒºè¯»å–æ•°æ®ï¼Œé¿å…äº†æ–‡ä»¶I/Oå’Œé¢å¤–çš„åº“ä¾èµ–ã€‚
        """
        # 1. è§¦å‘ç”»å¸ƒçš„ç»˜åˆ¶ï¼ˆrenderï¼‰
        fig.canvas.draw()

        width, height = fig.canvas.get_width_height()
        img_array = np.frombuffer(fig.canvas.tostring_argb(), dtype=np.uint8).reshape((height, width, 4))[:,:,1:]
        return img_array

    # å¦‚æœç‚¹å¤ªå¤šï¼Œè¿›è¡Œéšæœºé‡‡æ ·
    num_points = obj_P2.shape[0]
    if num_points > sample_k:
        indices = np.random.choice(num_points, sample_k, replace=False)
        obj_P2 = obj_P2[indices]
        pred_P2 = pred_P2[indices]

    # --- æ•°æ®å‡†å¤‡ ---
    # è®¡ç®—è¯¯å·®å‘é‡
    error_vectors = pred_P2 - obj_P2
    # è®¡ç®—æ¯ä¸ªç‚¹çš„è¯¯å·®å¤§å°ï¼ˆæ¬§æ°è·ç¦»ï¼‰
    error_magnitudes = np.linalg.norm(error_vectors, axis=1)

    if ranges is None:
        all_points = np.vstack([obj_P2, pred_P2])
        min_coords = all_points.min(axis=0)
        max_coords = all_points.max(axis=0)
        range_coords = max_coords - min_coords
        
        # é˜²æ­¢èŒƒå›´ä¸º0
        range_coords[range_coords == 0] = 1

        # å°†åæ ‡ç¼©æ”¾åˆ°ç”»å¸ƒå°ºå¯¸
        obj_scaled = (obj_P2 - min_coords) / range_coords * np.array([canvas_size[1], canvas_size[0]]) * 0.9 + 0.05 * np.array([canvas_size[1], canvas_size[0]])
        pred_scaled = (pred_P2 - min_coords) / range_coords * np.array([canvas_size[1], canvas_size[0]]) * 0.9 + 0.05 * np.array([canvas_size[1], canvas_size[0]])
    else:
        obj_scaled = obj_P2
        pred_scaled = pred_P2
        
    
    visualizations = {}

    fig_scatter, ax_scatter = plt.subplots(figsize=(10, 10))
    ax_scatter.scatter(obj_scaled[:, 0], obj_scaled[:, 1], c='blue', s=10, alpha=0.7, label='Ground Truth')
    ax_scatter.scatter(pred_scaled[:, 0], pred_scaled[:, 1], c='red', s=10, alpha=0.7, label='Prediction')
    ax_scatter.set_title('Ground Truth vs. Prediction Scatter Plot')

    if not ranges is None:
        ax_scatter.set_xlim(ranges[0][0],ranges[0][1])
        ax_scatter.set_ylim(ranges[1][0],ranges[1][1])

    ax_scatter.set_xlabel('X coordinate')
    ax_scatter.set_ylabel('Y coordinate')
    ax_scatter.set_aspect('equal', adjustable='box')
    ax_scatter.legend()
    ax_scatter.grid(True)
    visualizations['scatter'] = fig_to_numpy(fig_scatter)
    plt.close(fig_scatter)
    
    return visualizations

def get_overlap_area(corners_a, corners_b):
    corners_a = np.asarray(corners_a, dtype=float)
    corners_b = np.asarray(corners_b, dtype=float)

    # å…¼å®¹ (1,4,2)/(4,2)
    if corners_a.ndim == 3:
        corners_a = corners_a[0]
    if corners_b.ndim == 3:
        corners_b = corners_b[0]

    if corners_a.shape != (4, 2) or corners_b.shape != (4, 2):
        raise ValueError(f"corners å¿…é¡»å¯è§£æä¸º (4,2)ã€‚å½“å‰: A={corners_a.shape}, B={corners_b.shape}")

    poly_a = Polygon(corners_a)
    poly_b = Polygon(corners_b)

    if (not poly_a.is_valid) or (not poly_b.is_valid):
        # å¯¹æå°‘æ•°è‡ªäº¤/é€€åŒ–æƒ…å†µåšä¿®å¤
        poly_a = poly_a.buffer(0)
        poly_b = poly_b.buffer(0)

    inter = poly_a.intersection(poly_b)

    return inter.area

def sample_points_in_overlap(corners_a, corners_b, K, shrink=0.9, seed=None, max_iter_factor=200):
    """
    åœ¨ä¸¤ä¸ªå››è¾¹å½¢çš„é‡å åŒºåŸŸå†…é‡‡æ · K ä¸ªå‡åŒ€éšæœºç‚¹ï¼Œå¹¶å°†é‡å åŒºåŸŸç›¸å¯¹è´¨å¿ƒç¼©æ”¾ shrink å€åå†é‡‡æ ·ã€‚

    å‚æ•°
    ----
    corners_a: (4,2) æˆ– (1,4,2)
    corners_b: (4,2) æˆ– (1,4,2)
    K: int, éœ€è¦é‡‡æ ·çš„ç‚¹æ•°
    shrink: float, ç¼©æ”¾ç³»æ•°ï¼ˆä¾‹å¦‚ 0.9ï¼‰
    seed: int|None
    max_iter_factor: int, æ‹’ç»é‡‡æ ·çš„æœ€å¤§å°è¯•æ¬¡æ•°ç³»æ•°ï¼ˆæœ€å¤§å°è¯•æ¬¡æ•°=K*max_iter_factorï¼‰

    è¿”å›
    ----
    pts: (K,2) numpy.ndarray

    å¼‚å¸¸
    ----
    ValueError: æ— é‡å /é‡å é¢ç§¯ä¸º0/ç¼©æ”¾åé¢ç§¯ä¸º0/é‡‡æ ·å¤±è´¥
    """
    rng = np.random.default_rng(seed)

    corners_a = np.asarray(corners_a, dtype=float)
    corners_b = np.asarray(corners_b, dtype=float)

    # å…¼å®¹ (1,4,2)/(4,2)
    if corners_a.ndim == 3:
        corners_a = corners_a[0]
    if corners_b.ndim == 3:
        corners_b = corners_b[0]

    if corners_a.shape != (4, 2) or corners_b.shape != (4, 2):
        raise ValueError(f"corners å¿…é¡»å¯è§£æä¸º (4,2)ã€‚å½“å‰: A={corners_a.shape}, B={corners_b.shape}")

    poly_a = Polygon(corners_a)
    poly_b = Polygon(corners_b)

    if (not poly_a.is_valid) or (not poly_b.is_valid):
        # å¯¹æå°‘æ•°è‡ªäº¤/é€€åŒ–æƒ…å†µåšä¿®å¤
        poly_a = poly_a.buffer(0)
        poly_b = poly_b.buffer(0)

    inter = poly_a.intersection(poly_b)

    # äº¤é›†å¯èƒ½æ˜¯ Polygon / MultiPolygon / GeometryCollection / LineString / empty
    if inter.is_empty or inter.area <= 1e-12:
        raise ValueError("ä¸¤ä¸ªå››è¾¹å½¢æ²¡æœ‰æœ‰æ•ˆçš„é¢çŠ¶é‡å åŒºåŸŸï¼ˆäº¤é›†ä¸ºç©ºæˆ–é¢ç§¯â‰ˆ0ï¼‰ã€‚")

    # å¦‚æœæ˜¯ MultiPolygonï¼Œå–é¢ç§¯æœ€å¤§çš„é‚£å—ï¼ˆæœ€å¸¸ç”¨ã€ä¹Ÿæœ€åˆç†çš„é»˜è®¤ï¼‰
    if inter.geom_type == "MultiPolygon":
        inter = max(inter.geoms, key=lambda g: g.area)

    if inter.geom_type != "Polygon":
        # ä¾‹å¦‚ GeometryCollection ä¸­å¯èƒ½åŒ…å« Polygon + LineString ç­‰
        # è¿™é‡ŒæŠ½å–å…¶ä¸­é¢ç§¯æœ€å¤§çš„ Polygon
        polys = [g for g in getattr(inter, "geoms", []) if g.geom_type == "Polygon" and g.area > 1e-12]
        if not polys:
            raise ValueError(f"äº¤é›†ä¸æ˜¯å¯ç”¨çš„ Polygonï¼ˆå½“å‰ç±»å‹: {inter.geom_type}ï¼‰ã€‚")
        inter = max(polys, key=lambda g: g.area)

    # ç›¸å¯¹è´¨å¿ƒç¼©æ”¾ shrink å€
    c = inter.centroid
    inter_shrunk = scale(inter, xfact=shrink, yfact=shrink, origin=(c.x, c.y))

    if inter_shrunk.is_empty or inter_shrunk.area <= 1e-12:
        raise ValueError("é‡å åŒºåŸŸç¼©æ”¾åé¢ç§¯â‰ˆ0ï¼Œæ— æ³•é‡‡æ ·ã€‚è¯·æ£€æŸ¥ shrink æˆ–è¾“å…¥å››è¾¹å½¢ã€‚")

    # æ‹’ç»é‡‡æ ·ï¼šåœ¨ç¼©æ”¾åå¤šè¾¹å½¢çš„åŒ…å›´ç›’å†…å‡åŒ€é‡‡æ ·ï¼Œå†ç­›é€‰è½åœ¨å¤šè¾¹å½¢å†…
    minx, miny, maxx, maxy = inter_shrunk.bounds

    pts = []
    need = K
    max_tries = K * max_iter_factor
    tries = 0

    # ä¸ºæå‡æ•ˆç‡ï¼šæ¯æ¬¡æ‰¹é‡é‡‡æ ·
    while need > 0 and tries < max_tries:
        batch = max(need * 5, 256)  # è‡ªé€‚åº”æ‰¹é‡å¤§å°
        xs = rng.uniform(minx, maxx, size=batch)
        ys = rng.uniform(miny, maxy, size=batch)

        for x, y in zip(xs, ys):
            tries += 1
            if inter_shrunk.contains(Point(x, y)):
                pts.append((x, y))
                need -= 1
                if need == 0:
                    break
            if tries >= max_tries:
                break

    if len(pts) != K:
        raise ValueError(
            f"é‡‡æ ·å¤±è´¥ï¼šåœ¨æœ€å¤§å°è¯•æ¬¡æ•° {max_tries} å†…ä»…é‡‡åˆ° {len(pts)} ä¸ªç‚¹ã€‚"
            "ï¼ˆé‡å åŒºåŸŸå¯èƒ½å¤ªå°/è¿‡äºç‹­é•¿ï¼Œå¯å¢å¤§ max_iter_factor æˆ–å‡å° Kï¼‰"
        )
    
    return np.asarray(pts, dtype=float)


class Status(Enum):
    NOT_INIT = 0
    WELL_TRAINED = 1
    BAD_TRAINED = 2
