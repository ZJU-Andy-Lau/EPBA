import torch
import torch.nn as nn
import torch.nn.functional as F

from torchvision import transforms

import numpy as np
import cv2
from shapely.geometry import Polygon, box
import os
import typing
from typing import List,Tuple
import yaml

if typing.TYPE_CHECKING:
    from model.encoder import Encoder
    from rs_image import RSImage
    from pair import Pair

def load_config(path):
    with open(path,'r') as f:
        config = yaml.safe_load(f)
    return config

def warp_quads(corners, values:List[np.ndarray], output_size=(512, 512)):
        
        # 1. åŸºç¡€å‚æ•°è§£æ
        batched = True
        if corners.ndim < 3:
            corners = corners[None]
            batched = False
        B = corners.shape[0]
        target_h, target_w = output_size

        dst_pts_rc = np.array([
            [0, 0],                     # Top-Left
            [0, target_w - 1],          # Top-Right
            [target_h - 1, target_w - 1], # Bottom-Right
            [target_h - 1, 0]           # Bottom-Left
        ], dtype=np.float32)

            
        warped_values = []
        Hs = []

        # 4. å¾ªç¯å¤„ç†æ¯ä¸ªå››è¾¹å½¢
        for i in range(B):
            src_pts_rc = corners[i].astype(np.float32)
            src_pts_xy = src_pts_rc[:, ::-1] # (row, col) -> (col, row) / (y, x) -> (x, y)
            dst_pts_xy = dst_pts_rc[:, ::-1] 
            H_xy = cv2.getPerspectiveTransform(src_pts_xy, dst_pts_xy)
            
            warped_value_i = []

            for value in values:
                warped_value = cv2.warpPerspective(
                    value, 
                    H_xy, 
                    (target_w, target_h), 
                    flags=cv2.INTER_LINEAR
                )
                warped_value_i.append(warped_value)

            H_rc = H_xy.copy()
            H_rc[:, [0, 1]] = H_rc[:, [1, 0]]
            H_rc[[0, 1], :] = H_rc[[1, 0], :]
            
            warped_values.append(warped_value_i)
            Hs.append(H_rc)

        values_res = []
        for i in range(len(values)):
            values_res.append(
                 np.stack([
                      warped_values[j][i] for j in range(len(warped_values))
                 ],axis=0)
            )
        Hs = np.stack(Hs,axis=0)

        if not batched:
            values_res = values_res[0]
            Hs = Hs[0]

        return values_res,Hs

def find_intersection(corners):
    """
    è®¡ç®—å¤šä¸ªå‡¸å››è¾¹å½¢çš„å…±åŒé‡å åŒºåŸŸï¼ˆäº¤é›†ï¼‰ã€‚

    Args:
        corners (np.ndarray): å½¢çŠ¶ä¸º (B, 4, 2) çš„æ•°ç»„ã€‚
                              å­˜å‚¨ B ä¸ªå‡¸å››è¾¹å½¢çš„é¡¶ç‚¹åæ ‡ï¼Œæ ¼å¼ä¸º (x, y)ã€‚
                              é¡ºåºå¯ä»¥æ˜¯é¡ºæ—¶é’ˆæˆ–é€†æ—¶é’ˆã€‚

    Returns:
        intersection_coords (np.ndarray): å½¢çŠ¶ä¸º (N, 2) çš„æ•°ç»„ï¼Œè®°å½•é‡å åŒºåŸŸå¤šè¾¹å½¢çš„é¡¶ç‚¹ã€‚
                                          åæ ‡æ ¼å¼ä¿æŒä¸º (x, y)ã€‚
                                          å¦‚æœæ— é‡å ï¼Œè¿”å›ç©ºæ•°ç»„ (0, 2)ã€‚
    """
    B = corners.shape[0]
    if B == 0:
        return np.empty((0, 2))

    # 1. å°†ç¬¬ä¸€ä¸ªå››è¾¹å½¢ä½œä¸ºåˆå§‹äº¤é›†åŒºåŸŸ
    # shapely æ¥å—çš„è¾“å…¥æœ¬æ¥å°±æ˜¯ (x, y) åºåˆ—ï¼Œç°åœ¨è¯­ä¹‰å®Œå…¨åŒ¹é…
    current_poly = Polygon(corners[0])

    if not current_poly.is_valid:
        # å°è¯•ä¿®å¤æ— æ•ˆçš„å¤šè¾¹å½¢ï¼ˆä¾‹å¦‚è‡ªç›¸äº¤ï¼‰
        current_poly = current_poly.buffer(0)

    # 2. è¿­ä»£ä¸å…¶ä½™å››è¾¹å½¢æ±‚äº¤é›†
    for i in range(1, B):
        next_poly = Polygon(corners[i])
        
        if not next_poly.is_valid:
            next_poly = next_poly.buffer(0)

        # è®¡ç®—äº¤é›†
        current_poly = current_poly.intersection(next_poly)

        # å¦‚æœäº¤é›†å˜ä¸ºç©ºï¼Œå¯ä»¥æå‰ç»“æŸ
        if current_poly.is_empty:
            return np.empty((0, 2))

    # 3. è§£æç»“æœ
    
    if current_poly.is_empty:
        return np.empty((0, 2))
    
    if current_poly.geom_type == 'Polygon':
        # exterior.coords è¿”å›çš„æ˜¯ä¸€ç³»åˆ—ç‚¹
        coords = np.array(current_poly.exterior.coords)
        # å»é™¤æœ€åä¸€ä¸ªé‡å¤çš„é—­åˆç‚¹
        if len(coords) > 0 and np.allclose(coords[0], coords[-1]):
            coords = coords[:-1]
        return coords
    
    elif current_poly.geom_type in ['Point', 'MultiPoint', 'LineString']:
        # å¦‚æœäº¤é›†é€€åŒ–ä¸ºç‚¹æˆ–çº¿
        if hasattr(current_poly, 'coords'):
             return np.array(current_poly.coords)
        elif hasattr(current_poly, 'geoms'): # MultiPoint
             all_coords = []
             for geom in current_poly.geoms:
                 all_coords.extend(geom.coords)
             return np.array(all_coords)
        else:
             return np.empty((0, 2))
    else:
        return np.empty((0, 2))
    
def convert_diags_to_tlbr(diags: np.ndarray) -> np.ndarray:    
    tlbr = diags.copy() 
    tlbr[:, 1, 1] = diags[:, 0, 1]
    tlbr[:, 0, 1] = diags[:, 1, 1]
    return tlbr

def find_squares(corners, a_max, a_min=1.0, target_area_ratio = 0.5):
    """
    åœ¨å‡¸å¤šè¾¹å½¢å†…åˆ’åˆ†æ­£æ–¹å½¢ï¼Œé€šè¿‡è¿­ä»£ç¼©å°è¾¹é•¿ aï¼Œç›´åˆ°å¡«å……é¢ç§¯è¶…è¿‡å¤šè¾¹å½¢é¢ç§¯çš„ä¸€å®šæ¯”ä¾‹ã€‚

    Args:
        corners (np.ndarray): å½¢çŠ¶ä¸º (N, 2) çš„æ•°ç»„ï¼Œè®°å½•å¤šè¾¹å½¢é¡¶ç‚¹ (x, y)ã€‚
        a_max (float): æ­£æ–¹å½¢è¾¹é•¿çš„åˆå§‹è¿­ä»£å€¼ã€‚
        a_min (float): æ­£æ–¹å½¢è¾¹é•¿çš„æœ€å°é™åˆ¶ï¼Œå½“ current_a < a_min æ—¶åœæ­¢è¿­ä»£ã€‚
        target_area_ratio (float): ç›®æ ‡é¢ç§¯æ¯”ä¾‹ã€‚

    Returns:
        squares (np.ndarray): å½¢çŠ¶ä¸º (M, 2, 2) çš„æ•°ç»„ã€‚
                              M ä¸ºæ­£æ–¹å½¢æ•°é‡ã€‚
                              æ¯ä¸ªæ­£æ–¹å½¢ç”± [å·¦ä¸Šè§’(x,y), å³ä¸‹è§’(x,y)] ç»„æˆã€‚
    """
    # 1. åˆ›å»ºå¤šè¾¹å½¢å¹¶è®¡ç®—ç›®æ ‡é¢ç§¯
    poly = Polygon(corners)
    if not poly.is_valid:
        poly = poly.buffer(0)
        
    poly_area = poly.area
    target_area = target_area_ratio * poly_area
    
    # è·å–è¾¹ç•Œæ¡†
    min_x, min_y, max_x, max_y = poly.bounds
    
    current_a = float(a_max)
    
    # ç”¨äºæ˜¾ç¤ºçš„è¿­ä»£è®¡æ•°å™¨
    iteration = 0
    
    # è¿­ä»£å¾ªç¯ï¼šåªè¦å½“å‰è¾¹é•¿å¤§äºç­‰äºæœ€å°è¾¹é•¿ï¼Œå°±ç»§ç»­å°è¯•
    while current_a >= a_min:
        best_squares_for_this_a = []
        max_count_for_this_a = -1
        
        # --- æ”¹è¿›éƒ¨åˆ†ï¼šç½‘æ ¼åç§»æœç´¢ ---
        # ä¸ä»…ä»…ä» min_x, min_y å¼€å§‹ï¼Œè€Œæ˜¯å°è¯•åœ¨ [0, a) èŒƒå›´å†…å¹³ç§»ç½‘æ ¼
        search_steps = 10 
        
        # ç”Ÿæˆåç§»é‡æ•°ç»„
        offsets_x = np.linspace(0, current_a, search_steps, endpoint=False)
        offsets_y = np.linspace(0, current_a, search_steps, endpoint=False)
        
        for off_x in offsets_x:
            for off_y in offsets_y:
                current_candidates = []
                
                # åŸºäºå½“å‰åç§»é‡ç”Ÿæˆç½‘æ ¼èµ·å§‹ç‚¹
                start_x = min_x + off_x
                start_y = min_y + off_y
                
                # ç”Ÿæˆç½‘æ ¼
                # æ³¨æ„èŒƒå›´è¦ç¨å¾®å¤§ä¸€ç‚¹ä»¥è¦†ç›–æ•´ä¸ªå¤šè¾¹å½¢
                epsilon = 1e-9
                x_range = np.arange(start_x, max_x + epsilon, current_a)
                y_range = np.arange(start_y, max_y + epsilon, current_a)
                
                for x in x_range:
                    for y in y_range:
                        # å¿«é€Ÿé¢„ç­›é€‰ï¼šå¦‚æœæ­£æ–¹å½¢å®Œå…¨åœ¨è¾¹ç•Œæ¡†å¤–ï¼Œç›´æ¥è·³è¿‡ (ä¼˜åŒ–æ€§èƒ½)
                        if x > max_x or y > max_y:
                            continue
                            
                        # æ„å»ºæ­£æ–¹å½¢
                        sq_poly = box(x, y, x + current_a, y + current_a)
                        
                        # ä¸¥æ ¼æ£€æŸ¥åŒ…å«å…³ç³»
                        if poly.contains(sq_poly):
                            current_candidates.append([
                                [x, y], 
                                [x + current_a, y + current_a]
                            ])
                
                # å¦‚æœå½“å‰åç§»æ‰¾åˆ°çš„æ­£æ–¹å½¢æ›´å¤šï¼Œåˆ™æ›´æ–°æœ€ä½³æ–¹æ¡ˆ
                if len(current_candidates) > max_count_for_this_a:
                    max_count_for_this_a = len(current_candidates)
                    best_squares_for_this_a = current_candidates

        # è®¡ç®—å½“å‰æœ€ä½³è¦†ç›–ç‡
        current_coverage = max_count_for_this_a * (current_a ** 2)
        
        # 4. æ£€æŸ¥æ˜¯å¦æ»¡è¶³åœæ­¢æ¡ä»¶
        if current_coverage > target_area:
            return convert_diags_to_tlbr(np.array(best_squares_for_this_a))
        
        # 5. æ›´æ–°è¿­ä»£å‚æ•°
        current_a /= 2.0
        iteration += 1
        
    print(f"Warning: Minimum edge length ({a_min}) reached without meeting area threshold.")
    return np.array([])

def quadsplit_diags(diags:np.ndarray) -> np.ndarray:
    diags = diags.astype(float)
    x_tl = diags[:, 0, 0]  # (N,)
    y_tl = diags[:, 0, 1]  # (N,)
    x_br = diags[:, 1, 0]  # (N,)
    y_br = diags[:, 1, 1]  # (N,)
    x_mid = (x_tl + x_br) / 2.0  # (N,)
    y_mid = (y_tl + y_br) / 2.0  # (N,)
    q1 = np.stack([
        np.stack([x_tl, y_tl], axis=1), 
        np.stack([x_mid, y_mid], axis=1)
    ], axis=1) # (N, 2, 2)
    q2 = np.stack([
        np.stack([x_mid, y_tl], axis=1), 
        np.stack([x_br, y_mid], axis=1)
    ], axis=1) # (N, 2, 2)
    q3 = np.stack([
        np.stack([x_tl, y_mid], axis=1), 
        np.stack([x_mid, y_br], axis=1)
    ], axis=1) # (N, 2, 2)
    q4 = np.stack([
        np.stack([x_mid, y_mid], axis=1), 
        np.stack([x_br, y_br], axis=1)
    ], axis=1) # (N, 2, 2)

    new_diags = np.stack([q1, q2, q3, q4], axis=1).reshape(-1,2,2)
    
    return new_diags

feats_type = Tuple[torch.Tensor,torch.Tensor,torch.Tensor]

def extract_features(encoder:'Encoder',imgs_a:np.ndarray,imgs_b:np.ndarray,device:str = 'cuda') -> Tuple[feats_type,feats_type]:
    """
    Args:
        encoder: Encoder
        imgs_a: np.ndarray, (N,H,W,3)
        imgs_b: np.ndarray, (N,H,W,3)
        device: str

    Returns:
        feats
    """
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
        ])
    input_a = torch.stack([transform(img) for img in imgs_a],dim=0) # N,3,H,W
    input_b = torch.stack([transform(img) for img in imgs_b],dim=0) # N,3,H,W
    encoder = encoder.to(device).eval()
    input_a = input_a.to(device)
    input_b = input_b.to(device)

    feats_a,feats_b = encoder(input_a,input_b)

    return feats_a,feats_b

def get_coord_mat(h,w,b = 0,ds = 1,device = 'cuda'):
    """
    Args:
        h: ä¸‹é‡‡æ ·åçš„é«˜åº¦
        w: ä¸‹é‡‡æ ·åçš„å®½åº¦
        b: batchsize
        ds: ä¸‹é‡‡æ ·å€ç‡
        device: str
    
    Returns:
        coords: torch.Tensor, (b,h,w,2), (row,col)
    """
    grid_row, grid_col = torch.meshgrid(torch.arange(h, device=device, dtype=torch.float32), torch.arange(w, device=device, dtype=torch.float32), indexing='ij')
    coords_row = grid_row * ds + ds / 2.0
    coords_col = grid_col * ds + ds / 2.0
    coords = torch.stack([coords_row,coords_col],dim=-1) # h,w,2
    if b > 0:
        coords = torch.stack([coords] * b,dim=0) # b,h,w,2
    return coords

def apply_H(coords:torch.Tensor,Hs:torch.Tensor,device:str = 'cpu'):
    """
    coords: B,N,2
    Hs: B,3,3

    return: B,N,2
    """
    B,N = coords.shape[:2]
    coords = coords.permute(0,2,1) # B,2,N
    ones = torch.ones(B, 1, N, device=device)
    coords_homo = torch.cat([coords,ones],dim=1) # B,3,N
    coords_trans_homo = torch.bmm(Hs,coords_homo) # (B,3,3) @ (B,3,N) -> (B,3,N)
    eps = 1e-7
    z = coords_trans_homo[:, 2:3, :]
    coords_trans = coords_trans_homo[:, :2, :] / (z + eps) # B,2,N
    return coords_trans.permute(0,2,1) # B,N,2

def apply_M(coords:torch.Tensor,Ms:torch.Tensor,device:str = 'cpu'):
    """
    coords: B,N,2
    Ms: B,2,3

    return: B,N,2
    """
    B,N = coords.shape[:2]
    coords = coords.permute(0,2,1) # B,2,N
    ones = torch.ones(B, 1, N, device=device)
    coords_homo = torch.cat([coords,ones],dim=1) # B,3,N
    coords_trans = torch.bmm(Ms,coords_homo) # (B,2,3) @ (B,3,N) -> (B,2,N)
    return coords_trans.permute(0,2,1) # B,N,2

def solve_weighted_affine(src: torch.Tensor, dst: torch.Tensor, scores: torch.Tensor, eps: float = 1e-10) -> torch.Tensor:
    """
    ä½¿ç”¨åŠ æƒæœ€å°äºŒä¹˜æ³•è®¡ç®—ä» src åˆ° dst çš„ä»¿å°„å˜æ¢çŸ©é˜µã€‚

    Args:
        src (torch.Tensor): æºç‚¹åæ ‡ï¼Œå½¢çŠ¶ä¸º (N, 2)ã€‚
        dst (torch.Tensor): ç›®æ ‡ç‚¹åæ ‡ï¼Œå½¢çŠ¶ä¸º (N, 2)ã€‚
        scores (torch.Tensor): æ¯ä¸ªç‚¹çš„ç½®ä¿¡åº¦æƒé‡ï¼Œå½¢çŠ¶ä¸º (N,)ã€‚
        eps (float): é˜²æ­¢é™¤é›¶æˆ–æ•°å€¼ä¸ç¨³å®šçš„å¾®å°å€¼ã€‚

    Returns:
        torch.Tensor: ä»¿å°„å˜æ¢çŸ©é˜µï¼Œå½¢çŠ¶ä¸º (2, 3)ã€‚
                      æ ¼å¼ä¸º [[a, b, tx], [c, d, ty]]ã€‚
    """
    # 1. æ£€æŸ¥è¾“å…¥å½¢çŠ¶
    if src.ndim != 2 or src.shape[1] != 2:
        raise ValueError(f"src shape must be (N, 2), got {src.shape}")
    if dst.ndim != 2 or dst.shape[1] != 2:
        raise ValueError(f"dst shape must be (N, 2), got {dst.shape}")
    if scores.ndim != 1 or scores.shape[0] != src.shape[0]:
        raise ValueError(f"scores shape must be (N,), got {scores.shape}")
    
    # 2. ç¡®ä¿æ•°æ®ç±»å‹ä¸ºæµ®ç‚¹å‹ (lstsq éœ€è¦ float) ä¸”è®¾å¤‡ä¸€è‡´
    # å¦‚æœè¾“å…¥æ˜¯ intï¼Œå¿…é¡»è½¬ä¸º float
    if not src.is_floating_point():
        src = src.float()
    if not dst.is_floating_point():
        dst = dst.float()
    if not scores.is_floating_point():
        scores = scores.float()

    # ç¡®ä¿æ‰€æœ‰å¼ é‡åœ¨åŒä¸€è®¾å¤‡
    device = src.device
    if dst.device != device or scores.device != device:
        raise RuntimeError("All input tensors (src, dst, scores) must be on the same device.")

    N = src.shape[0]

    # 3. æ„å»ºå¢å¹¿çŸ©é˜µ (Augmented Matrix)
    # src_aug = [x, y, 1]
    ones = torch.ones(N, 1, device=device, dtype=src.dtype)
    src_aug = torch.cat([src, ones], dim=1)  # å½¢çŠ¶: (N, 3)

    # 4. åº”ç”¨æƒé‡ (Weighted Least Squares)
    # æ ¸å¿ƒåŸç†: æœ€å°åŒ– sum( w_i * ||Ax_i - b_i||^2 )
    # ç­‰ä»·äºæ±‚è§£çº¿æ€§æ–¹ç¨‹: sqrt(W) * A * X = sqrt(W) * B
    
    # è®¡ç®—æƒé‡çš„å¹³æ–¹æ ¹
    # æ³¨æ„: è¿™é‡Œçš„ eps å¾ˆé‡è¦ï¼Œé˜²æ­¢æƒé‡ä¸º0æ—¶å‡ºç°æ•°å€¼é—®é¢˜
    weights_sqrt = torch.sqrt(torch.clamp(scores, min=0) + eps).view(-1, 1) # å½¢çŠ¶: (N, 1)

    # åˆ©ç”¨å¹¿æ’­æœºåˆ¶å¯¹çŸ©é˜µçš„æ¯ä¸€è¡Œè¿›è¡ŒåŠ æƒ
    A_weighted = src_aug * weights_sqrt  # å½¢çŠ¶: (N, 3)
    B_weighted = dst * weights_sqrt      # å½¢çŠ¶: (N, 2)

    # 5. æ±‚è§£çº¿æ€§æ–¹ç¨‹ç»„
    # æ±‚è§£ A_weighted @ X = B_weighted
    # torch.linalg.lstsq åœ¨ GPU ä¸Šä¹Ÿèƒ½é«˜æ•ˆè¿è¡Œ
    # driver='gels' æ˜¯æ±‚è§£ä¸€èˆ¬çŸ©é˜µæœ€å°äºŒä¹˜çš„æ ‡å‡†é©±åŠ¨
    try:
        result = torch.linalg.lstsq(A_weighted, B_weighted, driver='gels')
    except RuntimeError:
        # å¦‚æœ gels å¤±è´¥ï¼ˆæå°‘æ•°æƒ…å†µï¼‰ï¼Œå›é€€åˆ° gelsd (åŸºäºSVDï¼Œæ›´ç¨³å¥ä½†ç¨æ…¢)
        result = torch.linalg.lstsq(A_weighted, B_weighted, driver='gelsd')
        
    X = result.solution  # å½¢çŠ¶: (3, 2)

    # 6. æ ¼å¼åŒ–è¾“å‡º (3, 2) -> (2, 3)
    affine_matrix = X.t()

    return affine_matrix

def is_overlap(image_a:'RSImage',image_b:'RSImage',min_area:float = 0.):
    poly1 = Polygon(image_a.corner_xys)
    poly2 = Polygon(image_b.corner_xys)
    overlap_area = poly1.intersection(poly2).area
    return overlap_area >= min_area

def convert_pair_dicts_to_solver_inputs(
    pair_list,
    device = None,
    dtype = torch.float32,
):
    if device is None:
        first_tensor = None
        for d in pair_list:
            for v in d.values():
                first_tensor = v
                break
            if first_tensor is not None:
                break
        if first_tensor is not None and isinstance(first_tensor, torch.Tensor):
            device = first_tensor.device
        else:
            device = torch.device("cpu")

    edge_src_list: List[int] = []
    edge_dst_list: List[int] = []
    A_list: List[torch.Tensor] = []
    t_list: List[torch.Tensor] = []

    # 3. éå†æ¯ä¸ªæ— å‘è¾¹ dictï¼Œæ‹†æˆä¸¤æ¡æœ‰å‘è¾¹
    for d in pair_list:
        if len(d) != 2:
            raise ValueError(
                f"pair_list ä¸­çš„ dict æœŸæœ›æ°å¥½æœ‰ä¸¤ä¸ª keyï¼ˆå¯¹åº”ä¸€å¯¹èŠ‚ç‚¹ï¼‰ï¼Œä½†å®é™… len={len(d)}ã€‚å†…å®¹={d}"
            )

        # ä¾‹å¦‚ d = {i: M_i_j, j: M_j_i}
        ids = list(d.keys())
        i, j = ids[0], ids[1]

        M_i_j = d[i]
        M_j_i = d[j]

        # æ£€æŸ¥è¾“å…¥ tensor å½¢çŠ¶
        if not (isinstance(M_i_j, torch.Tensor) and M_i_j.shape == (2, 3)):
            raise ValueError(f"M_{i}_to_{j} çš„å½¢çŠ¶ä¸æ˜¯ (2,3)ï¼Œå®é™…ä¸º {M_i_j.shape}")
        if not (isinstance(M_j_i, torch.Tensor) and M_j_i.shape == (2, 3)):
            raise ValueError(f"M_{j}_to_{i} çš„å½¢çŠ¶ä¸æ˜¯ (2,3)ï¼Œå®é™…ä¸º {M_j_i.shape}")

        # ç»Ÿä¸€åˆ°æŒ‡å®š device / dtype
        M_i_j = M_i_j.to(device=device, dtype=dtype)
        M_j_i = M_j_i.to(device=device, dtype=dtype)

        # ä» (2,3) ä¸­æ‹†å‡º A (2,2) å’Œ t (2,)
        A_i_j = M_i_j[:, :2]  # çº¿æ€§éƒ¨åˆ†
        t_i_j = M_i_j[:, 2]   # å¹³ç§»éƒ¨åˆ†

        A_j_i = M_j_i[:, :2]
        t_j_i = M_j_i[:, 2]

        # æœ‰å‘è¾¹ i -> j
        edge_src_list.append(i)
        edge_dst_list.append(j)
        A_list.append(A_i_j)
        t_list.append(t_i_j)

        # æœ‰å‘è¾¹ j -> i
        edge_src_list.append(j)
        edge_dst_list.append(i)
        A_list.append(A_j_i)
        t_list.append(t_j_i)

    # 4. è½¬ä¸ºç»Ÿä¸€çš„ tensor å½¢å¼
    edge_src = torch.tensor(edge_src_list, dtype=torch.long, device=device)
    edge_dst = torch.tensor(edge_dst_list, dtype=torch.long, device=device)
    A_ij = torch.stack(A_list, dim=0).to(device=device, dtype=dtype)   # (E,2,2)
    t_ij = torch.stack(t_list, dim=0).to(device=device, dtype=dtype)   # (E,2)

    # 5. æƒé‡å…ˆå…¨éƒ¨è®¾ä¸º 1.0
    w_ij = torch.ones(edge_src.shape[0], dtype=dtype, device=device)

    return edge_src, edge_dst, A_ij, t_ij, w_ij

def avg_downsample(tensor:torch.Tensor, k: int) -> torch.Tensor:
    if tensor.ndim < 3:
        raise ValueError(f"è¾“å…¥å¼ é‡çš„ç»´åº¦å¿…é¡» >= 3ï¼Œå½“å‰ç»´åº¦ä¸º {tensor.ndim}")
        
    H, W = tensor.shape[1:3]
    if H % k != 0 or W % k != 0:
        raise ValueError(
            f"å¼ é‡çš„ H ({H}) å’Œ W ({W}) ç»´åº¦å¿…é¡»èƒ½è¢«ä¸‹é‡‡æ ·å€æ•° K ({k}) æ•´é™¤ã€‚"
        )

    rest_dims = tensor.shape[3:]
    num_channels = torch.prod(torch.tensor(rest_dims)).item() if len(rest_dims) > 0 else 1
    if len(rest_dims) == 0:
        reshaped_tensor = tensor.unsqueeze(-1) # å½¢çŠ¶å˜ä¸º (B, H, W, 1)
    else:
        reshaped_tensor = tensor.view(tensor.shape[0], H, W, num_channels)

    transposed_tensor = reshaped_tensor.permute(0, 3, 1, 2)
    downsampled_transposed = F.avg_pool2d(
        input=transposed_tensor,
        kernel_size=k,
        stride=k
    ) # å½¢çŠ¶ï¼š(B, C, H//K, W//K)

    final_tensor_flat = downsampled_transposed.permute(0, 2, 3, 1)
    output_shape = (
        tensor.shape[0], 
        H // k, 
        W // k
    ) + rest_dims
    
    final_tensor = final_tensor_flat.view(output_shape)
    
    return final_tensor

def haversine_distance(coords1: np.ndarray, coords2: np.ndarray) -> np.ndarray:
    """è®¡ç®—ä¸¤ç»„ (lat, lon) åæ ‡ä¹‹é—´çš„ Haversine è·ç¦» (ç±³)"""
    R = 6371000 
    lat1 = coords1[:, 0]
    lon1 = coords1[:, 1]
    lat2 = coords2[:, 0]
    lon2 = coords2[:, 1]

    lat1_rad = np.radians(lat1)
    lon1_rad = np.radians(lon1)
    lat2_rad = np.radians(lat2)
    lon2_rad = np.radians(lon2)

    dlat = lat2_rad - lat1_rad
    dlon = lon2_rad - lon1_rad

    a = np.sin(dlat / 2)**2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(dlon / 2)**2
    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))
    distance = R * c
    
    return distance

def get_error_report(pairs:List['Pair']):
    all_distances_list = []
    for pair in pairs:
        distances = pair.check_error()
        all_distances_list.append(distances)
    all_distances = np.concatenate(all_distances_list)
    total_points = len(all_distances)
    report = {
        'mean': float(np.mean(all_distances)),
        'median': float(np.median(all_distances)),
        'max': float(np.max(all_distances)),
        'rmse': float(np.sqrt(np.mean(all_distances**2))),
        'count': int(total_points),
        '<1m_percent': float(((all_distances < 1.0).sum() / total_points) * 100),
        '<3m_percent': float(((all_distances < 3.0).sum() / total_points) * 100),
        '<5m_percent': float(((all_distances < 5.0).sum() / total_points) * 100),
    }
    return report

def check_invalid_tensors(tensor_list: List[torch.Tensor]):
    """
    æ£€æŸ¥ List[torch.Tensor] ä¸­çš„æ¯ä¸ªå¼ é‡æ˜¯å¦å«æœ‰ NaN (éæ•°å­—) æˆ– Inf (æ— ç©·å¤§) å€¼ã€‚
    å¦‚æœå‘ç°å¼‚å¸¸å€¼ï¼Œåˆ™æ‰“å°è¯¥å¼ é‡åœ¨ List ä¸­çš„ç´¢å¼•ã€‚

    Args:
        tensor_list (List[torch.Tensor]): å¾…æ£€æŸ¥çš„ PyTorch å¼ é‡åˆ—è¡¨ã€‚
    """
    
    # è®¡æ•°å™¨ç”¨äºè®°å½•å‘ç°çš„å¼‚å¸¸å¼ é‡æ•°é‡
    abnormal_count = 0
    
    print("--- å¼€å§‹æ£€æŸ¥ PyTorch å¼ é‡åˆ—è¡¨ä¸­çš„ NaN/Inf å€¼ ---")
    
    for idx, tensor in enumerate(tensor_list):
        # ä»…æ£€æŸ¥æµ®ç‚¹æ•°å¼ é‡ï¼Œå› ä¸ºæ•´æ•°å¼ é‡é€šå¸¸ä¸åŒ…å« NaN/Inf
        if tensor.dtype.is_floating_point:
            
            # 1. æ£€æŸ¥ NaN
            # torch.isnan(tensor).any() å¦‚æœå¼ é‡ä¸­è‡³å°‘æœ‰ä¸€ä¸ª NaNï¼Œåˆ™è¿”å› True
            has_nan = torch.isnan(tensor).any()
            
            # 2. æ£€æŸ¥ Inf
            # torch.isinf(tensor).any() å¦‚æœå¼ é‡ä¸­è‡³å°‘æœ‰ä¸€ä¸ª Â±Infï¼Œåˆ™è¿”å› True
            has_inf = torch.isinf(tensor).any()
            
            if has_nan or has_inf:
                abnormal_count += 1
                
                # æ„é€ åŒ…å«å…·ä½“å¼‚å¸¸ç±»å‹çš„æŠ¥å‘Š
                report = []
                if has_nan:
                    report.append("NaN")
                if has_inf:
                    report.append("Inf")
                
                print(f"ğŸš¨ å¼‚å¸¸å¼ é‡å‘ç°ï¼šç´¢å¼• {idx} åŒ…å«ä»¥ä¸‹å€¼: {', '.join(report)}ã€‚")
                print(f"    - å½¢çŠ¶: {tensor.shape}")
                print(f"    - æ•°æ®ç±»å‹: {tensor.dtype}")
        
    if abnormal_count == 0:
        print("âœ… æ£€æŸ¥å®Œæ¯•ï¼šæ‰€æœ‰å¼ é‡å‡æœªå‘ç° NaN æˆ– Inf å€¼ã€‚")
    else:
        print(f"âš ï¸ æ£€æŸ¥å®Œæ¯•ï¼šå…±å‘ç° {abnormal_count} ä¸ªå¼‚å¸¸å¼ é‡ã€‚")